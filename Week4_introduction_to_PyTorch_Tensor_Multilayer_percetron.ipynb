{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl/i4N5yZcer3PcOfzMpS2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JLee823/2023-1st-AI-assisted-drug-discovery-SNU/blob/main/Week4_introduction_to_PyTorch_Tensor_Multilayer_percetron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텐서, 다중 퍼셉트론의 기초\n",
        "------\n",
        "본 수업에서는 딥러닝의 기초가 되는 텐서와 다중 퍼셉트론의 기초 개념에 대해서 다루어 본다. \n",
        "\n",
        "본 노트는 University of Amsterdam의 deep learning tutorial 강좌와 위키 독스의 파이토치로 시작하는 딥러닝 입문에서 많이 참고하였습니다. \n",
        " \n",
        "본 수업에서는 다양한 딥러닝 라이브러리(tensorflow, caffe, Theano 등)중에서 현재 가장 널리 사용되고 있는 파이토치 라이브러리를 사용한다. \n",
        "\n",
        "2023년 3월 현재 파이토치에 관한 다양한 온라인 material들이 있으며, 자세한 설명이 필요할 경우에는 다음의 material들을 참고할 수 있다. \n",
        "* 파이토치 한국어 튜토리얼: https://tutorials.pytorch.kr/\n",
        "* 파이토치 60분만에 끝내기: https://tutorials.pytorch.kr/beginner/deep_learning_60min_blitz.html\n",
        "* PyTorch로 시작하는 딥 러닝 입문: https://wikidocs.net/book/2788\n",
        "* University of Amsterdam, deep learning tutorial: https://github.com/phlippe/uvadlc_notebooks\n",
        "\n",
        "파이토치는 다음과 같이 불러 올 수 있다. \n",
        "\n"
      ],
      "metadata": {
        "id": "faQeSrati-XF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oEXAj5qi0AV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 강의노트를 작성하는 2023년 3월 현재 colab에서 기본으로 제공되는 PyTorch 버젼은 1.13.1이다. "
      ],
      "metadata": {
        "id": "-1zrHwdsnANZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "S9q3qFOLmswW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서(Tensor)\n",
        "--------\n",
        "텐서는 벡터(vector)와 행렬(matrix)과 유사하게 숫자들이 일정한 index를 가지고 배열되어 있는 데이터 형태이다. \n",
        "\n",
        "이는 수치 계산을 빠르게 하기 위한 라이브러리인 numpy의 array와 유사하다. \n",
        " \n",
        "사실 우리가 잘 아는 scalar, vector, matrix는 텐서의 특수한 경우이다. \n",
        "\n",
        "scalar는 rank 0의 텐서이고, vector는 rank 1의 텐서, matrix는 rank 2의 텐서이다. "
      ],
      "metadata": {
        "id": "wM8YA9QukpGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://hkilter.com/images/7/7a/Tensors.png\" width=800>"
      ],
      "metadata": {
        "id": "R4G3ZEXdk_6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 초기화 \n",
        "\n",
        "텐서는 다음과 같이 리스트로 부터 초기화 할 수 있다. "
      ],
      "metadata": {
        "id": "GT28hOM2mYOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "7shJi6JWkgLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 생성된 x_data는 2X2 형태의 tensor (matrix) 이다. "
      ],
      "metadata": {
        "id": "MXc4_iJ6mbs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data"
      ],
      "metadata": {
        "id": "G1fHqErTmSQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data.shape"
      ],
      "metadata": {
        "id": "3sV2h__Dmg0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NumPy 배열로부터 생성하기\n",
        "\n",
        "텐서는 NumPy 배열로 생성할 수 있다. "
      ],
      "metadata": {
        "id": "Sj6-tpn9mxWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "XYLmP7M1mlWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 랜덤한 텐서 초기화\n",
        "\n",
        "다음과 같은 방식으로 임의의 값이 들어가 있는 무작위 텐서를 초기화 할 수 있다. \n",
        "\n",
        "무작위 텐서를 매번 동일하게 생성되도록 하기 위해서 random seed를 고정시켜 준다. \n"
      ],
      "metadata": {
        "id": "0tBMwO0XnYNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) # Setting the seed"
      ],
      "metadata": {
        "id": "FxoMzvz3m5-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "Tw1TAxzwnnEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.Tensor`는 주어진 크기의 텐서를 생성한다. \n",
        "\n",
        "무작위 텐선 뿐만 아니라 다음의 함수를 사용하면 다양한 텐서들을 초기화 할 수 있다. \n",
        "\n",
        "* `torch.zeros`: 0으로 채운 텐서\n",
        "* `torch.ones`: 1로 채운 텐서\n",
        "* `torch.rand`: 0~1 사이의 무작위 값으로 채워진 텐서\n",
        "* `torch.randn`: 평균이 0이고 표준편차가 1인 정규 분포를 따르는 무작위 값으로 채워진 텐서\n",
        "* `torch.arange`: $N,N+1,N+2,...,M$ 의 값을 가지는 텐서\n",
        "* `torch.Tensor` (input list): 주어진 input 값을 가진 텐서"
      ],
      "metadata": {
        "id": "HFOIw54RoKKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
        "x = torch.rand(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "XhKnBTU2ntzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서의 크기는 x.shape과 x.size를 통해서 확인할 수 있다. "
      ],
      "metadata": {
        "id": "uKJEo4NipAFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = x.shape\n",
        "print(\"Shape:\", x.shape)\n",
        "\n",
        "size = x.size()\n",
        "print(\"Size:\", size)\n",
        "\n",
        "dim1, dim2, dim3 = x.size()\n",
        "print(\"Size:\", dim1, dim2, dim3)"
      ],
      "metadata": {
        "id": "iuzlV1ejo8p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서 연산 \n",
        "------"
      ],
      "metadata": {
        "id": "pKYhPyDiufWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 덧셈 연산\n",
        "\n",
        "파이토치에서 제공하는 다양한 텐서 연산에 대한 문서는 다음에서 찾을 수 있다. \n",
        "\n",
        "[PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#)\n",
        "\n",
        "본 노트에서는 중요한 몇 가지의 예시를 리뷰하도록 한다. \n",
        "\n",
        "가장 기본적인 연산은 덧셈 연산이다. \n"
      ],
      "metadata": {
        "id": "HJomSZCZpT7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ],
      "metadata": {
        "id": "acP7uqZZpHVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "당연하게도 두 개의 텐서의 크기가 다르면 덧셈(뺄셈)이 불가능하다. "
      ],
      "metadata": {
        "id": "-3un7yS1yYFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 4)\n",
        "y=x1+x2"
      ],
      "metadata": {
        "id": "3NVdoX5JyPhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그러나 [브로드캐스팅](https://pytorch.org/docs/stable/notes/broadcasting.html)이라는 기능 때문에 크기가 다르더라도 덧셈이 가능한 경우가 있다. \n"
      ],
      "metadata": {
        "id": "oOfMSbGozAM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.tensor([1,2,3,4])\n",
        "x2 = torch.tensor([2]) \n",
        "print(x1.shape)\n",
        "print(x2.shape)\n",
        "print(x1+x2)\n"
      ],
      "metadata": {
        "id": "AMvPqYq7y_Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다차원의 경우에도 가능\n",
        "x1 = torch.rand(2,3)\n",
        "x2 = torch.tensor([1])\n",
        "print(x1)\n",
        "print(x1+x2)"
      ],
      "metadata": {
        "id": "ls7Um0dXzzws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### view 연산\n",
        "--------\n",
        "\n",
        "파이토치에서 많이 사용되는 텐서 연산 중의 하나는 텐서의 크기 변환이다. \n",
        "\n",
        "텐서의 크기는 view라는 method를 이용해서 다음과 같이 수행할 수 있다. "
      ],
      "metadata": {
        "id": "ZLfiJ3HVrvuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(6)\n",
        "print(\"X\", x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "E94uxk6Lp1Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 텐서는 scalar 값 6개를 가지고 있는 1차원 텐서이다. \n",
        "\n",
        "위 텐서를 2차원 텐서로 다음과 같이 변환 할 수 있다. "
      ],
      "metadata": {
        "id": "OrsA63g5sABa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "YhahfUz1r8VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**index에 -1이 들어가면 해당 차원은 파이토치가 알아서 채우도록 한다는 뜻이다.**"
      ],
      "metadata": {
        "id": "Xp9vRjoQs7EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(12)\n",
        "x=x.view(-1, 3) # \n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "giERNWzDstpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=x.view(-1, 4)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "Scm0YhkUtCj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드는 12개짜리 숫자를 3 X 2 X 2 형태의 3차원 텐서로 변환시킨다. "
      ],
      "metadata": {
        "id": "9Q1SzFTTupE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=x.view(3, -1, 2)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "fvxaiP79uBLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "view를 수행할 때, 전체 숫자의 개수에는 변화가 없다. \n",
        "\n",
        "그러므로 차원의 수가 맞지 않으면 에러를 준다. \n",
        "\n",
        "다음의 코드를 보자. "
      ],
      "metadata": {
        "id": "b2VegETUuHWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=x.view(-1, 5)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "-pw22QKItAYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "즉 view에서는 숫자들을 새로운 방식으로 정렬하게 되는데 이 때, 가장 앞에 있는 차원부터 순서대로 채워지도록 약속되어 있습니다. \n"
      ],
      "metadata": {
        "id": "ifD7eYo6u-x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.stack.imgur.com/ORqaP.png\" width=800>"
      ],
      "metadata": {
        "id": "9yKxKbRsuLbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.stack.imgur.com/26Q9g.png\" width=800>"
      ],
      "metadata": {
        "id": "mJo95e48vJzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\b다시 말해, view는 다음과 같은 규칙을 가지고 있습니다. \n",
        "\n",
        "* view는 기본적으로 변경 전과 변경 후의 텐서 안의 원소의 개수가 유지되어야 합니다.\n",
        "\n",
        "* 파이토치의 view는 사이즈가 -1로 설정되면 다른 차원으로부터 해당 값을 유추합니다."
      ],
      "metadata": {
        "id": "vhdjHVLNsek_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Permute 연산\n",
        "-------\n",
        "permute는 두 개의 차원을 서로 바꾸어 줍니다. \n"
      ],
      "metadata": {
        "id": "sW7IEAlTvRNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(6)\n",
        "x=x.view(2,3)\n",
        "print(\"X (before):\\n\", x)\n",
        "print(\"--------\")\n",
        "x = x.permute(1, 0) # 0번째 차원과 1번째 차원 (열과 행)을 서로 교환한다. 2X3 => 3X2 \n",
        "print(\"X (after) :\\n\", x)"
      ],
      "metadata": {
        "id": "g5v89YBvsMg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 텐서의 곱 (tensor multiplication)\n",
        "-------\n",
        "\n",
        "파이토치에서 텐서 연산은 기본적으로 각 성분 별로 이루어지도록 되어 있습니다. \n",
        "\n",
        "다음의 예시를 봅시다. \n",
        "\n"
      ],
      "metadata": {
        "id": "JwOSJVOzx15F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([1,2,3])\n",
        "y=torch.tensor([2,3,4])\n",
        "print(x*y)"
      ],
      "metadata": {
        "id": "9zVyZ1s3yJmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리가 익숙한 벡터의 내적이나 행렬의 곱과 달리 각 원소 별로 곱셈이 이루어지게 됩니다. \n",
        "\n",
        "그러므로 기본적으로 텐서의 크기가 동일해야 연산이 가능합니다. \n",
        "\n",
        "그러나 텐서의 크기가 다르더라도 텐서의 크기를 암묵적으로 확장하여 계산을 수행하는 경우들이 있는데 이를 **브로드캐스팅**이라고 부릅니다. \n"
      ],
      "metadata": {
        "id": "4kuRwaTlz64Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([1,2,3])\n",
        "y=torch.tensor([2])\n",
        "print(x.size())\n",
        "print(y.size())\n",
        "print(x*y)"
      ],
      "metadata": {
        "id": "LtCf9XwOz5_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 예제에서 1X3의 크기를 가진 텐서와 텐서 [2]는 사실상 [2, 2, 2]로 확장되었다. \n",
        "\n",
        "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_1.png\" width=600>"
      ],
      "metadata": {
        "id": "ybz1Llx20Vfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같은 브로드캐스팅은 다음의 조건을 만족할 때, 가능하다. \n",
        "1. 가장 마지막 차원(가장 오른쪽)의 차원이 동일해야 한다.\n",
        "2. 또는 차원의 값이 1이어야 한다. \n",
        "\n",
        "두 개의 텐서는 동일한 차원을 가질 필요는 없다. \n",
        "\n",
        "브로드캐스팅이 일어날 때는 둘 중에 더 큰 차원을 따라가도록 작동한다. \n",
        "\n"
      ],
      "metadata": {
        "id": "6xRKjwlE05jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예를 들어서 크기가 서로 다른 아래의 두 개의 텐서 연산이 일어나면 최종적인 결과물은 아래와 같다. \n",
        "\n",
        "\n",
        "> A      (4d array):  8 x 1 x 6 x 1\n",
        ">\n",
        "> B      (3d array):      7 x 1 x 5\n",
        "> \n",
        "> Result (4d array):  8 x 7 x 6 x 5\n",
        "\n",
        "즉, 차원 값이 1인 차원은 다른 연산의 대상이 되는 텐서의 차원 값을 따라가면서 확장이 일어난다. "
      ],
      "metadata": {
        "id": "FrwVaHB12Asz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[ 0.0,  0.0,  0.0],\n",
        "              [10.0, 10.0, 10.0],\n",
        "              [20.0, 20.0, 20.0],\n",
        "              [30.0, 30.0, 30.0]])\n",
        "b = torch.tensor([1.0, 2.0, 3.0])\n",
        "c = a+b\n",
        "print(a.size())\n",
        "print(b.size())\n",
        "print(c.size())\n",
        "print(c)"
      ],
      "metadata": {
        "id": "vOWt4mdf05CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_2.png\" width=800>\n",
        "\n",
        "1차원 텐서가 2차원 텐서로 확장이 이루어졌다. "
      ],
      "metadata": {
        "id": "N1Oahn4V3Jm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
        "c = a + b"
      ],
      "metadata": {
        "id": "3BvufP3V3B_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_3.png\" width=600>\n",
        "\n",
        "그러나 마지막 차원의 크기가 맞지 않으면 broadcasting이 이루어지지 않는다. "
      ],
      "metadata": {
        "id": "9AgKoG573TX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 예제 처럼 차원 확장을 통한 계산도 가능하다. \n",
        "\n",
        "np.newaxis는 존재하지 않던 차원을 확장하도록 해주는 기능을 가진다.  "
      ],
      "metadata": {
        "id": "wtIg_H7o3ple"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([0.0, 10.0, 20.0, 30.0])\n",
        "b = torch.tensor([1.0, 2.0, 3.0])\n",
        "c = a[:, np.newaxis] # [4] -> [4,1] 차원의 2차원 텐서로 변환되었다. \n",
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(c.shape)\n",
        "print(c + b) "
      ],
      "metadata": {
        "id": "XF4Xq5C53oc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_4.png\" width=600>"
      ],
      "metadata": {
        "id": "J8ei6J7k3g1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### matrix multiplication\n",
        "------\n",
        "딥러닝에서 가장 많이 사용되는 연산은 바로 행렬의 곱입니다. \n",
        "\n",
        "많은 경우, 입력 벡터 $\\mathbf{x}$를 받아서 학습된 가중치 행렬 $\\mathbf{W}$를 사용하여 변환되는 경우가 많습니다 \n",
        "\n",
        "행렬 곱셈을 수행하는 여러 가지 함수가 파이토치에서는 구현되어 있다. \n",
        "\n",
        "그 중 일부는 다음과 같습니다:\n",
        "\n",
        "* `torch.matul`: 두 개의 텐서에 대해 행렬 곱을 수행한다. 여기서 특정 동작은 차원에 따라 달라집니다. 두 입력이 모두 행렬(2차원 텐서)인 경우 표준 행렬 곱을 수행한다. 고차원 입력의 경우 이 기능은 브로드캐스트를 지원한다. \n",
        "(자세한 내용은 [manual](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul) 참조). **numpy와 비슷하게 a @ b로도 쓸 수 있다.**\n",
        "* `torch.mm`: 두 개의 행렬에 걸쳐 행렬 곱을 수행하지만 브로드 캐스트 기능은 지원하지 않는다([설명](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm)  참조)\n",
        "* `torch.bmm`: 지원 배치 차원으로 매트릭스 제품을 수행한다. 첫 번째 텐서 $T$가 모양($b\\times n\\times m$)이고 두 번째 텐서 $R$($b\\times m\\times p$)인 경우 출력 $O$는 모양($b\\times n\\times p$)이며 $T$와 $R$의 하위 행렬의 $b$ 행렬 곱셈을 수행한다. \n",
        "* `torch.einsum`: 아인슈타인 합계 규칙을 사용하여 행렬 곱셈 등(즉, 곱셈)을 수행합니다. \n",
        "\n",
        "보통 **torch.matul**이나 **torch.bmm**을 많이 사용합니다. \n",
        "\n",
        "아래의 `torch.matul`을 사용하여 행렬 곱셈을 시도할 수 있습니다."
      ],
      "metadata": {
        "id": "25KOJ-z8wIr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(6)\n",
        "x = x.view(2, 3)\n",
        "print(\"X\\n\", x)"
      ],
      "metadata": {
        "id": "Uit_rcFVvgRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
        "print(\"W\\n\", W)"
      ],
      "metadata": {
        "id": "_kNujiSG4Xa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
        "print(\"h \\n\", h)"
      ],
      "metadata": {
        "id": "NY9-BsKw4ZaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 인덱싱(Indexing)\n",
        "\n",
        "일반적인 파이썬의 iterable과 같이 인덱싱이 가능하다. \n",
        " "
      ],
      "metadata": {
        "id": "hYaoxwcu6UPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "9Iy5GfQY4apf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:, 1])   # Second column"
      ],
      "metadata": {
        "id": "c630o7UX7Xcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0])      # First row"
      ],
      "metadata": {
        "id": "RO2C7B9h7bQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:2, -1]) # First two rows, last column"
      ],
      "metadata": {
        "id": "fEhfPeXQ7blN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[1:3, :]) # Middle two rows"
      ],
      "metadata": {
        "id": "_uBgaS4k7d6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 퍼셉트론\n",
        "------\n",
        "\n",
        "딥러닝에서 가장 기본이 되는 개념은 퍼셉트론이라고 하는 개념이다. \n",
        "\n",
        "퍼셉트론은 1957년 프랑크 로젠블라트에 의해서 제안되었으며, 초창기에는 아주 간단한 선형 분류만 가능한 모델이었으나 다층 퍼셉트론을 이용하면 더 복잡한 모델을 구성할 수 있다는 것을 발견하였다. \n",
        "\n",
        "퍼셉트론은 신경 세포의 구조를 모사한 것이다. \n",
        "\n"
      ],
      "metadata": {
        "id": "gwMKQzMW9pXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Neuron.svg/800px-Neuron.svg.png\" width=600>"
      ],
      "metadata": {
        "id": "ruxkggBl_FO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.nomidl.com/wp-content/uploads/2022/04/image-5.png\" width=600>\n"
      ],
      "metadata": {
        "id": "4egxLGgL_Or_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적으로 perceptron은 $n$차원의 입력 $x_1$, $x_2$, $x_3$, $\\dots$, $x_n$을 받아서 이 입력의 **선형 결합** $\\sum w_i x_i + b$으로 근사한다. \n",
        "\n",
        "그 후, 선형 결합으로 얻은 값을 **비선형 활성 함수(activation function)**에 한 번 더 통과시켜 최종적인 추정 값을 얻는다. \n",
        "\n",
        "$\\hat{y}=f(\\sum w_i x_i + b)$ \n",
        "\n",
        "여기에서 $f$는 비선형의 활성함수이다. \n",
        "\n",
        "비선형의 활성함수를 이용하는 이유는 선형 결합의 선형 결합을 여러번 취하더라도 그 결과는 선형이기 때문에 선형이 아닌 관계를 추론하기 위해서는 반드시 비선형의 활성함수가 중간에 필요하다. \n",
        "\n"
      ],
      "metadata": {
        "id": "6WDK2cgc_dsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하나의 퍼셉트론이 아니라 여러개의 퍼셉트론을 사용할 경우는 다음과 같이 그림으로 나타낼 수 있다. \n",
        "\n",
        "<img src=\"https://python-course.eu/images/machine-learning/example_network_3_4_2_without_bias.webp\" width=600>"
      ],
      "metadata": {
        "id": "gaFzJt5jAkHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 3차원의 입력을 받아서 4차원의 출력으로 바꾸는 연산은 다음의 행렬 곱으로 나타낼 수 있다. \n",
        "\n",
        "$\n",
        "f\\left[\\begin{pmatrix}\n",
        "x_1\\\\\n",
        "x_2\\\\\n",
        "x_3\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "w_{11} w_{12} w_{13} w_{14} \\\\\n",
        "w_{21} w_{22} w_{23} w_{24} \\\\\n",
        "w_{31} w_{32} w_{33} w_{34} \\\\\n",
        "\\end{pmatrix}\n",
        "+\n",
        "\\begin{pmatrix}\n",
        "b_1\\\\\n",
        "b_2\\\\\n",
        "b_3\\\\\n",
        "b_4\n",
        "\\end{pmatrix}\\right]\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "h_1\\\\\n",
        "h_2\\\\\n",
        "h_3\\\\\n",
        "h_4\\\\\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "이 때, $f$는 활성 함수이고, 입력 차원은 3차원이고 숨겨진 차원은 4차원이다. \n",
        "\n"
      ],
      "metadata": {
        "id": "cgKIdRETBn8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://static.javatpoint.com/tutorial/tensorflow/images/single-layer-perceptron-in-tensorflow.png\" width=500>\n",
        "\n"
      ],
      "metadata": {
        "id": "Mueb92vbDtRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "그 후, 최종 출력을 2차원으로 만들기 위해서는 4차원 입력을 2차원으로 바꾸어주는 두 번째 행렬을 곱해주면 된다. \n",
        "\n",
        "$\\mathbf{O} = \\mathbf{h}\\mathbf{W_2} + \\mathbf{b_2}$\n",
        "\n",
        "이 때, $\\mathbf{W_2}$의 형태는 $4 × 2$가 되어 4차원의 벡터를 2차원으로 변환시켜 준다. \n",
        "\n",
        "즉, 이렇게 여러개의 perceptron을 여러 층으로 쌓은 경우를 multi-layer perceptron(MLP)라고 부른다. \n",
        "\n",
        "그리고 multilayer perceptron은 결국 여러 층의 파라미터 행렬의 연산을 계속 수행하는 것이라고 이해할 수 있다. \n",
        "\n",
        "우리가 **학습**이라고 부르는 것은 원하는 목적 값(objective value)를 정확하게 예측하는 **파라미터들**, 또는 **가중치**라고도 부름, ($w_i$ 값)을 찾아내는 것이라고 할 수 있다. \n"
      ],
      "metadata": {
        "id": "q6slzTF4DUu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/publication/334609713/figure/fig1/AS:783455927406593@1563801857102/Multi-Layer-Perceptron-MLP-diagram-with-four-hidden-layers-and-a-collection-of-single_Q640.jpg\" width=600>"
      ],
      "metadata": {
        "id": "EgPjdJTDECpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝이라는 이름이 명명된 이유는 불과 20여년전의 인공 지능 모델만 하더라도 컴퓨터 메모리의 한계와 계산 속도의 한계로 인해서 hidden layer를 몇 층 정도만을 쌓을 수 있었다. \n",
        "\n",
        "그러나 GPU를 이용한 계산과 컴퓨터 메모리의 발전에 의해서 최근에는 수십, 수백층 까지의 layer를 쌓을 수 있게 되었다. \n",
        "\n",
        "그리고 이와 같이 매우 깊이 층을 쌓았을 때, 많은 문제에서 기존의 몇 개의 층을 쌓은 문제에 비해서 훨씬 정확한 결과를 얻을 수 있다는 것을 발견하였다. \n",
        "\n"
      ],
      "metadata": {
        "id": "6_vBOjTYEq97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음의 그래프는 image를 분류하는 ImageNet challenge의 정확도 향상을 보여준다. \n",
        "\n",
        "<img src=\"https://blog.roboflow.com/content/images/2021/06/image-18.png\" width=600>"
      ],
      "metadata": {
        "id": "h0Q_FY75FaUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/publication/332452649/figure/fig1/AS:770098897887234@1560617293964/Error-rates-on-the-ImageNet-Large-Scale-Visual-Recognition-Challenge-Accuracy.ppm\" width=600>\n",
        "\n",
        "딥러닝 방법이 처음 제안된 2012년부터 에러율이 급격히 낮아짐을 확인할 수 있다. \n",
        "\n",
        "2015년부터는 인간의 에러율을 넘어서는 성능을 보여주고 있다. "
      ],
      "metadata": {
        "id": "91XWG8ToFK3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 얻어진 최종적인 output 값을 원하는 true 값과 비교를 통해 손실 함수($L$)를 계산한다. \n",
        "\n",
        "얻어진 손실 함수의 값을 **최소화**하는 방향으로 파라미터들이 업데이트 된다. \n",
        "\n",
        "이를 수식으로 표현하면 다음과 같다. "
      ],
      "metadata": {
        "id": "l5lDYdHmEn8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$w_{i,\\mathrm{new}} = w_{i,\\mathrm{old}} - \\eta \\frac{\\partial L}{\\partial w_i}$"
      ],
      "metadata": {
        "id": "IhfqxyuvHknO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 계산 그래프와 역전파\n",
        "---------\n",
        "\n",
        "딥러닝이 폭발적으로 발전할 수 있었던 중요한 계기 중의 하나는 복잡한 손실 함수의 기울기를 빠르게 계산하여 파라미터를 효율적으로 업데이트 할 수 있었기 때문입니다. \n",
        "\n",
        "파이토치에서는 어떤 연산을 수행하면 내부적으로 연산에 참여한 모든 변수에 대한 기울기를 계산할 수 있는 기능을 가지고 있습니다. \n",
        "\n",
        "이는 계산 그래프와 역전파를 통해서 이루어집니다. \n",
        "\n",
        "다음의 예시를 봅시다. "
      ],
      "metadata": {
        "id": "gZJwGnP97tMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((3,))\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "3E8UKUGR7fai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적으로 텐서를 생성하면 gradient를 계산하지 않도록 초기화 됩니다. "
      ],
      "metadata": {
        "id": "3EZDITz0IWgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "-ZKkgOYTITU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 requires_grad_라는 method를 실행하면 주어진 텐서의 기울기를 계산하도록 설정되게 됩니다. "
      ],
      "metadata": {
        "id": "vmz3bzW_Ib4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "계산 그래프의 개념과 익숙해지기 위해서 다음의 함수를 생각해봅시다. \n",
        "\n",
        "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
        "\n",
        "위 식에서 $x$가 파라미터이고, 목적 값인 $y$를 최소화 또는 최대화 하는 것이 우리의 목표입니다. \n",
        "\n",
        "이를 위해서 $y$에 대한 편미분을 계산해야 합니다: $\\partial y / \\partial \\mathbf{x}$. \n",
        "\n",
        "본 예시에서는 $\\mathbf{x}=[0,1,2]$ 를 입력 값으로 사용합니다. "
      ],
      "metadata": {
        "id": "gvin5V0sIjPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3, dtype=torch.float32, requires_grad=True) # Only float tensors can have gradients\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "fRU4ntwbIUoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 함수 값을 얻기 위한 연산을 단계별로 나누어 보면 다음과 같이 쓸 수 있습니다. "
      ],
      "metadata": {
        "id": "Bk7LjNyXJKVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = x + 2\n",
        "b = a ** 2\n",
        "c = b + 3\n",
        "y = c.mean()\n",
        "print(\"Y\", y)"
      ],
      "metadata": {
        "id": "yBRPOTZrJG2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 위의 연산을 그래프로 나타내면 아래와 같습니다. "
      ],
      "metadata": {
        "id": "iD22KyHLJcxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/pytorch_computation_graph.svg?raw=1\" width=200>\n",
        "\n",
        "각 화살표는 하나의 연산에 해당합니다. \n",
        "\n",
        "이 때, 각 연산에 해당하는 미분 값을 빠르게 구할 수 있습니다. \n",
        "\n",
        "각 단계의 미분 값을 얻으면 이를 chain rule을 이용해서 연결하면, 최종적으로 우리가 원하는 변수의 기울기 값을 구할 수 있습니다. \n",
        "\n",
        "그렇기 때문에 최종적인 목적 함수 값 $y$에서 역으로 따라가면서 입력 값 $x$에 대한 미분 값을 얻게 되기 때문에 이를 backpropagation이라고 부릅니다. "
      ],
      "metadata": {
        "id": "_y_z_IwZJXLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "backpropagation은 다음의 명령을 통해서 수행됩니다. "
      ],
      "metadata": {
        "id": "rIQCC3KtKgOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "jmF203_TKjke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`x.grad` \b는 이제 $\\partial y/ \\partial \\mathcal{x}$ 값을 저장하게 됩니다. \n",
        "\n",
        "이 값은 입력 값인 $\\mathbf{x}=[0,1,2]$에서 $y$ 값의 변화량을 나타내게 됩니다. "
      ],
      "metadata": {
        "id": "XxhQ0vvwKllE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)"
      ],
      "metadata": {
        "id": "Hs0S4l2bK5qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 역전파를 수식으로 나타내면 다음과 같습니다. \n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$"
      ],
      "metadata": {
        "id": "Y-K7Lkc9J-Ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we have simplified this equation to index notation, and by using the fact that all operation besides the mean do not combine the elements in the tensor. The partial derivatives are:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial a_i}{\\partial x_i} = 1,\\hspace{1cm}\n",
        "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i\\hspace{1cm}\n",
        "\\frac{\\partial c_i}{\\partial b_i} = 1\\hspace{1cm}\n",
        "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "Hence, with the input being $\\mathbf{x}=[0,1,2]$, our gradients are $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$. The previous code cell should have printed the same result."
      ],
      "metadata": {
        "id": "zVCn2qOWKcZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU support\n",
        "------\n",
        "앞서 논의 했듯이 GPU를 이용한 계산이 딥러닝의 발전에 매우 중요한 역할을 하였습니다. \n",
        "\n",
        "GPU의 경우, 매우 단순한 연산(덧셈, 곱셈)을 평행하게 처리하는데 특화되어 있어서 특정 계산에 있어서는 CPU에 비해서 훨씬 빠른 성능을 보여줍니다. \n",
        "\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/comparison_CPU_GPU.png?raw=1\" width=\"700px\"></center>"
      ],
      "metadata": {
        "id": "FXRhPS4jLBZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 cell을 실행하면 여러분의 현재 colab 세션에서 GPU를 사용가능한지 보여줍니다. "
      ],
      "metadata": {
        "id": "MQbK09X2LneF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "_jiw8ibNJJ4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://devsoyoung.github.io/static/874712e6233d2209010f47e7229ff3d2/4f5bc/runtime.webp\" width=500>\n"
      ],
      "metadata": {
        "id": "LqYzhiQHLwTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/99924D345B435A7003\" width=600>"
      ],
      "metadata": {
        "id": "brTJYcwKMVaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 하드웨어 가속기를 GPU로 설정하면 gpu를 사용하실 수 있습니다. "
      ],
      "metadata": {
        "id": "-s06fFRwMkfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "eaX9H0daLv27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적으로 텐서가 정의되면 CPU에서 계산이 되게 되어 있습니다. \n",
        "\n",
        "텐서의 값이 GPU에서 계산되도록 하려면 `.to(...)`, 또는 `.cuda()` 함수를 이용해서 GPU에서 계산이 수행되도록 할 수 있습니다. \n",
        "\n",
        "또는 아래와 같이 `.device()` method를 이용해서 계산이 수행되는 플랫폼을 지정할 수 있습니다. "
      ],
      "metadata": {
        "id": "Ordf3yDbM9pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "TwssdwKzMxHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드를 이용하면 텐서를 선언하고 GPU에서 계산이 되도록 할 수 있다. "
      ],
      "metadata": {
        "id": "n06s_wHJNjrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 3)\n",
        "x = x.to(device)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "ECmedTnhNi8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음의 코드를 실행시키면 CPU와 GPU의 행렬 곱셈 연산에서의 속도 차이를 알 수 있다. "
      ],
      "metadata": {
        "id": "pqqhfdMYNiua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "## CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "## GPU version\n",
        "x = x.to(device)\n",
        "#_ = torch.matmul(x, x)  # First operation to 'burn in' GPU\n",
        "# CUDA is asynchronous, so we need to use different timing functions\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "_ = torch.matmul(x, x)\n",
        "end.record()\n",
        "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
      ],
      "metadata": {
        "id": "VDf0ogEaN3s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파이토치 기반의 multilayer perceptron 모델을 이용한 분자 독성 예측\n",
        "-------"
      ],
      "metadata": {
        "id": "yr6PKNdfOV2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YlsOfOxRNfDc"
      }
    }
  ]
}