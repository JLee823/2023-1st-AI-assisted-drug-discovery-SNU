{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOlWDwjn1dQJo+SFZd8Hgbl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JLee823/2023-1st-AI-assisted-drug-discovery-SNU/blob/main/Week4_introduction_to_PyTorch_Tensor_Multilayer_percetron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텐서, 다중 퍼셉트론의 기초\n",
        "------\n",
        "본 수업에서는 딥러닝의 기초가 되는 텐서와 다중 퍼셉트론의 기초 개념에 대해서 다루어 본다. \n",
        "\n",
        "본 노트는 University of Amsterdam의 deep learning tutorial 강좌와 위키 독스의 파이토치로 시작하는 딥러닝 입문에서 많이 참고하였습니다. \n",
        " \n",
        "본 수업에서는 다양한 딥러닝 라이브러리(tensorflow, caffe, Theano 등)중에서 현재 가장 널리 사용되고 있는 파이토치 라이브러리를 사용한다. \n",
        "\n",
        "2023년 3월 현재 파이토치에 관한 다양한 온라인 material들이 있으며, 자세한 설명이 필요할 경우에는 다음의 material들을 참고할 수 있다. \n",
        "* 파이토치 한국어 튜토리얼: https://tutorials.pytorch.kr/\n",
        "* 파이토치 60분만에 끝내기: https://tutorials.pytorch.kr/beginner/deep_learning_60min_blitz.html\n",
        "* PyTorch로 시작하는 딥 러닝 입문: https://wikidocs.net/book/2788\n",
        "* University of Amsterdam, deep learning tutorial: https://github.com/phlippe/uvadlc_notebooks\n",
        "* 신약 개발 및 분자 설계에 조금 더 관련이 있는 Andrew White의 deep learning material:\n",
        "https://dmol.pub/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "faQeSrati-XF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파이토치\n",
        "------"
      ],
      "metadata": {
        "id": "Xuo86szH0F6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치는 다음과 같이 불러 올 수 있다. \n"
      ],
      "metadata": {
        "id": "-naifwwN0D_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1oEXAj5qi0AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71344f8-fed8-46bf-beb4-32793033e8e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 1.13.1+cu116\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Using torch\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 강의노트를 작성하는 2023년 3월 현재 colab에서 기본으로 제공되는 PyTorch 버젼은 1.13.1이다.\n",
        "\n",
        "PyTorch 2.0 버젼이 공식적으로 공개되었으므로 조만간 2.0이 서비스 될 것으로 예상됩니다. "
      ],
      "metadata": {
        "id": "-1zrHwdsnANZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "S9q3qFOLmswW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서(Tensor)\n",
        "--------\n",
        "텐서는 벡터(vector)와 행렬(matrix)과 유사하게 숫자들이 일정한 index를 가지고 배열되어 있는 데이터 형태이다. \n",
        "\n",
        "이는 수치 계산을 빠르게 하기 위한 라이브러리인 numpy의 array와 유사하다. \n",
        " \n",
        "사실 우리가 잘 아는 scalar, vector, matrix는 텐서의 특수한 경우이다. \n",
        "\n",
        "scalar는 rank 0의 텐서이고, vector는 rank 1의 텐서, matrix는 rank 2의 텐서이다. "
      ],
      "metadata": {
        "id": "wM8YA9QukpGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://hkilter.com/images/7/7a/Tensors.png\" width=800>"
      ],
      "metadata": {
        "id": "R4G3ZEXdk_6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서 초기화 \n",
        "\n",
        "텐서는 다음과 같이 리스트로 부터 초기화 할 수 있다. "
      ],
      "metadata": {
        "id": "GT28hOM2mYOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "7shJi6JWkgLD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 생성된 x_data는 2X2 형태의 tensor (matrix) 이다. "
      ],
      "metadata": {
        "id": "MXc4_iJ6mbs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_data"
      ],
      "metadata": {
        "id": "G1fHqErTmSQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af81aeaa-af63-48f1-80e2-6413d13242a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data.shape"
      ],
      "metadata": {
        "id": "3sV2h__Dmg0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083a9821-6cfb-49ba-9a37-56ddbcd87b6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy 배열로부터 생성하기\n",
        "\n",
        "텐서는 NumPy 배열로 생성할 수 있다. "
      ],
      "metadata": {
        "id": "Sj6-tpn9mxWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "XYLmP7M1mlWS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 랜덤한 텐서 초기화\n",
        "\n",
        "다음과 같은 방식으로 임의의 값이 들어가 있는 무작위 텐서를 초기화 할 수 있다. \n",
        "\n",
        "무작위 텐서를 매번 동일하게 생성되도록 하기 위해서 random seed를 고정시켜 준다. \n"
      ],
      "metadata": {
        "id": "0tBMwO0XnYNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) # Setting the seed"
      ],
      "metadata": {
        "id": "FxoMzvz3m5-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483cf966-855b-402d-c16c-ecd25ee43e6c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbeb921ce10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "Tw1TAxzwnnEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6c7110-8fcb-4ed6-d238-7a5a8e9ea9c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0000e+00, 0.0000e+00, 1.3563e-19, 1.9517e-19],\n",
            "         [1.4013e-45, 2.3822e-44, 1.4013e-45, 2.5223e-44],\n",
            "         [2.8026e-44, 2.6099e+20, 3.5078e+30, 4.5827e-41]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 7.5553e+28, 5.2839e-11],\n",
            "         [1.4013e-45, 2.3822e-44, 1.4013e-45, 2.5223e-44],\n",
            "         [1.5428e-42, 6.7722e+22, 5.1216e-35, 0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.Tensor`는 주어진 크기의 텐서를 생성한다. \n",
        "\n",
        "무작위 텐선 뿐만 아니라 다음의 함수를 사용하면 다양한 텐서들을 초기화 할 수 있다. \n",
        "\n",
        "* `torch.zeros`: 0으로 채운 텐서\n",
        "* `torch.ones`: 1로 채운 텐서\n",
        "* `torch.rand`: 0~1 사이의 무작위 값으로 채워진 텐서\n",
        "* `torch.randn`: 평균이 0이고 표준편차가 1인 정규 분포를 따르는 무작위 값으로 채워진 텐서\n",
        "* `torch.arange`: $N,N+1,N+2,...,M$ 의 값을 가지는 텐서\n",
        "* `torch.Tensor` (input list): 주어진 input 값을 가진 텐서"
      ],
      "metadata": {
        "id": "HFOIw54RoKKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
        "x = torch.rand(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "XhKnBTU2ntzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "417d1318-b223-458d-aedd-cc56d6ece4a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "         [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "         [0.9408, 0.1332, 0.9346, 0.5936]],\n",
            "\n",
            "        [[0.8694, 0.5677, 0.7411, 0.4294],\n",
            "         [0.8854, 0.5739, 0.2666, 0.6274],\n",
            "         [0.2696, 0.4414, 0.2969, 0.8317]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서의 크기는 x.shape과 x.size를 통해서 확인할 수 있다. "
      ],
      "metadata": {
        "id": "uKJEo4NipAFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = x.shape\n",
        "print(\"Shape:\", x.shape)\n",
        "\n",
        "size = x.size()\n",
        "print(\"Size:\", size)\n",
        "\n",
        "dim1, dim2, dim3 = x.size()\n",
        "print(\"Size:\", dim1, dim2, dim3)"
      ],
      "metadata": {
        "id": "iuzlV1ejo8p_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452f9dd5-aa51-498d-c5e8-51a9b320ee72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([2, 3, 4])\n",
            "Size: torch.Size([2, 3, 4])\n",
            "Size: 2 3 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서 연산 \n",
        "------"
      ],
      "metadata": {
        "id": "pKYhPyDiufWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 덧셈 연산\n",
        "\n",
        "파이토치에서 제공하는 다양한 텐서 연산에 대한 문서는 다음에서 찾을 수 있다. \n",
        "\n",
        "[PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#)\n",
        "\n",
        "본 노트에서는 중요한 몇 가지의 예시를 리뷰하도록 한다. \n",
        "\n",
        "가장 기본적인 연산은 덧셈 연산이다. \n"
      ],
      "metadata": {
        "id": "HJomSZCZpT7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ],
      "metadata": {
        "id": "acP7uqZZpHVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0572aae2-e367-4d8d-eb7b-8900ff8a4b3e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X1 tensor([[0.1053, 0.2695, 0.3588],\n",
            "        [0.1994, 0.5472, 0.0062]])\n",
            "X2 tensor([[0.9516, 0.0753, 0.8860],\n",
            "        [0.5832, 0.3376, 0.8090]])\n",
            "Y tensor([[1.0569, 0.3448, 1.2448],\n",
            "        [0.7826, 0.8848, 0.8151]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "당연하게도 두 개의 텐서의 크기가 다르면 덧셈(뺄셈)이 불가능하다. "
      ],
      "metadata": {
        "id": "-3un7yS1yYFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 4)\n",
        "#y=x1+x2  # 이 연산은 불가능. "
      ],
      "metadata": {
        "id": "3NVdoX5JyPhx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "그러나 [브로드캐스팅](https://pytorch.org/docs/stable/notes/broadcasting.html)이라는 기능 때문에 크기가 다르더라도 덧셈이 가능한 경우가 있다. \n"
      ],
      "metadata": {
        "id": "oOfMSbGozAM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.tensor([1,2,3,4])\n",
        "x2 = torch.tensor([2]) \n",
        "print(x1.shape)\n",
        "print(x2.shape)\n",
        "print(x1+x2)\n"
      ],
      "metadata": {
        "id": "AMvPqYq7y_Xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa2bd520-8106-49be-ff3f-57d7353af934"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4])\n",
            "torch.Size([1])\n",
            "tensor([3, 4, 5, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다차원의 경우에도 가능\n",
        "x1 = torch.rand(2,3)\n",
        "x2 = torch.tensor([1])\n",
        "print(x1)\n",
        "print(x1+x2)"
      ],
      "metadata": {
        "id": "ls7Um0dXzzws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922c3c94-d4c0-49f7-9f80-d1a0b2f7a989"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0050, 0.3068, 0.1165],\n",
            "        [0.9103, 0.6440, 0.7071]])\n",
            "tensor([[1.0050, 1.3068, 1.1165],\n",
            "        [1.9103, 1.6440, 1.7071]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### view 연산\n",
        "--------\n",
        "\n",
        "파이토치에서 많이 사용되는 텐서 연산 중의 하나는 텐서의 크기 변환이다. \n",
        "\n",
        "텐서의 크기는 view라는 method를 이용해서 다음과 같이 수행할 수 있다. "
      ],
      "metadata": {
        "id": "ZLfiJ3HVrvuH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서의 차원 추가 및 제거\n",
        "-----\n",
        "\n",
        "이미 만들어진 텐서에 차원을 추가하거나 제거 할 수 있습니다. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rng4vcXUugak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 차원 추가\n",
        "\n",
        "다음 예시에서 1차원의 텐서에 np.newaxis를 이용하여 하나의 차원을 더 추가하는 것을 확인할 수 있습니다. "
      ],
      "metadata": {
        "id": "ngTXwxwSy3oJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([1,2,3,4])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "\n",
        "print(\"\\nAfter inserting a new axis at the end\")\n",
        "y=x[:,np.newaxis]\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "print(\"\\nAfter inserting a new axis at the first dimension\")\n",
        "y=x[np.newaxis, :]\n",
        "print(y)\n",
        "print(y.shape)\n"
      ],
      "metadata": {
        "id": "tW4axgldwlx1",
        "outputId": "9572da46-da7d-4b16-cf1d-a4ec4ce78470",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4])\n",
            "torch.Size([4])\n",
            "\n",
            "After inserting a new axis at the end\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "torch.Size([4, 1])\n",
            "\n",
            "After inserting a new axis at the first dimension\n",
            "tensor([[1, 2, 3, 4]])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor의 unsqueeze method를 이용해서도 차원 추가가 가능하다. "
      ],
      "metadata": {
        "id": "gWpY-FwdxYJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y=x.unsqueeze(0) # 0번째 인덱스에 차원 추가\n",
        "print(y)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "O1dgFECoxh5b",
        "outputId": "93c4cb30-e695-441d-cb3e-614d318f6eee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4]])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=x.unsqueeze(1) # 1번째 인덱스에 차원 추가\n",
        "print(y)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "2_qGK5ubxzYR",
        "outputId": "b85f575f-a4ad-4f58-9d2e-d31ad4c0c58e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "torch.Size([4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([[1,2,3],[2,3,4]])\n",
        "print(x.shape)\n",
        "y=x.unsqueeze(-1) # 마지막 차원에 차원 추가\n",
        "print(y)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "g_n0N3Oyx3Qn",
        "outputId": "dc5b5433-6d77-4519-a791-34265e1f861a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "tensor([[[1],\n",
            "         [2],\n",
            "         [3]],\n",
            "\n",
            "        [[2],\n",
            "         [3],\n",
            "         [4]]])\n",
            "torch.Size([2, 3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "차원 추가는 view를 통해서도 가능하다. "
      ],
      "metadata": {
        "id": "kKZQFV7ZyO_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 차원 제거\n",
        "\n",
        "차원의 크기가 1인 차원을 squeeze를 이용해서 제거할 수 있다. "
      ],
      "metadata": {
        "id": "v0wBQ0NSyHCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([[1,2,3,4]])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(\"After squeeze\")\n",
        "y=x.squeeze()\n",
        "print(y)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "YysDqMrXy5C4",
        "outputId": "955801a5-059b-45f9-a447-8ad3872133bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 4]])\n",
            "torch.Size([1, 4])\n",
            "After squeeze\n",
            "tensor([1, 2, 3, 4])\n",
            "torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(6)\n",
        "print(\"X\", x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "E94uxk6Lp1Vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b0e96a-162c-4e88-c838-41f1c84a849a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([0, 1, 2, 3, 4, 5])\n",
            "torch.Size([6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 텐서는 scalar 값 6개를 가지고 있는 1차원 텐서이다. \n",
        "\n",
        "위 텐서를 2차원 텐서로 다음과 같이 변환 할 수 있다. "
      ],
      "metadata": {
        "id": "OrsA63g5sABa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "YhahfUz1r8VD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d38225a-7089-4441-a94c-8cce9893f30a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**index에 -1이 들어가면 해당 차원은 파이토치가 알아서 채우도록 한다는 뜻이다.**"
      ],
      "metadata": {
        "id": "Xp9vRjoQs7EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(12)\n",
        "x=x.view(-1, 3) # \n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "giERNWzDstpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92007d4c-f519-4e76-8e96-a2969bb4bbf3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2],\n",
            "        [ 3,  4,  5],\n",
            "        [ 6,  7,  8],\n",
            "        [ 9, 10, 11]])\n",
            "torch.Size([4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=x.view(-1, 4)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "Scm0YhkUtCj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0df4023-35a0-4937-e023-dcbd04b803b3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드는 12개짜리 숫자를 3 X 2 X 2 형태의 3차원 텐서로 변환시킨다. "
      ],
      "metadata": {
        "id": "9Q1SzFTTupE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=x.view(3, -1, 2)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "fvxaiP79uBLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf5bd0c-6bce-4011-bdd8-cfc00da67409"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1],\n",
            "         [ 2,  3]],\n",
            "\n",
            "        [[ 4,  5],\n",
            "         [ 6,  7]],\n",
            "\n",
            "        [[ 8,  9],\n",
            "         [10, 11]]])\n",
            "torch.Size([3, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "view를 수행할 때, 전체 숫자의 개수에는 변화가 없다. \n",
        "\n",
        "그러므로 차원의 수가 맞지 않으면 에러를 준다. \n",
        "\n",
        "다음의 코드를 보자. "
      ],
      "metadata": {
        "id": "b2VegETUuHWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x=x.view(-1, 5)  # Error!\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "-pw22QKItAYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36e3c7b-0fa4-45a2-c6d5-f3eb34e1265f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0,  1],\n",
            "         [ 2,  3]],\n",
            "\n",
            "        [[ 4,  5],\n",
            "         [ 6,  7]],\n",
            "\n",
            "        [[ 8,  9],\n",
            "         [10, 11]]])\n",
            "torch.Size([3, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "즉 view에서는 숫자들을 새로운 방식으로 정렬하게 되는데 이 때, 가장 앞에 있는 차원부터 순서대로 채워지도록 약속되어 있습니다. \n"
      ],
      "metadata": {
        "id": "ifD7eYo6u-x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.stack.imgur.com/ORqaP.png\" width=800>"
      ],
      "metadata": {
        "id": "9yKxKbRsuLbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://i.stack.imgur.com/26Q9g.png\" width=800>"
      ],
      "metadata": {
        "id": "mJo95e48vJzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\b다시 말해, view는 다음과 같은 규칙을 가지고 있습니다. \n",
        "\n",
        "* view는 기본적으로 변경 전과 변경 후의 텐서 안의 원소의 개수가 유지되어야 합니다.\n",
        "\n",
        "* 파이토치의 view는 사이즈가 -1로 설정되면 다른 차원으로부터 해당 값을 유추합니다."
      ],
      "metadata": {
        "id": "vhdjHVLNsek_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Permute 연산\n",
        "-------\n",
        "permute는 두 개의 차원을 서로 바꾸어 줍니다. \n"
      ],
      "metadata": {
        "id": "sW7IEAlTvRNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.arange(6)\n",
        "x=x.view(2,3)\n",
        "print(\"X (before):\\n\", x)\n",
        "print(\"--------\")\n",
        "x = x.permute(1, 0) # 0번째 차원과 1번째 차원 (열과 행)을 서로 교환한다. 2X3 => 3X2 \n",
        "print(\"X (after) :\\n\", x)"
      ],
      "metadata": {
        "id": "g5v89YBvsMg9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee478e4d-2e0d-45c3-eec2-6cafb126dc05"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X (before):\n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "--------\n",
            "X (after) :\n",
            " tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서의 곱 (tensor multiplication)\n",
        "-------\n",
        "\n",
        "파이토치에서 텐서 연산은 기본적으로 각 성분 별로 이루어지도록 되어 있습니다. \n",
        "\n",
        "다음의 예시를 봅시다. \n",
        "\n"
      ],
      "metadata": {
        "id": "JwOSJVOzx15F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([1,2,3])\n",
        "y=torch.tensor([2,3,4])\n",
        "print(x*y)"
      ],
      "metadata": {
        "id": "9zVyZ1s3yJmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77074bf-2617-490d-917a-5f7d6ee3fb51"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2,  6, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리가 익숙한 벡터의 내적이나 행렬의 곱과 달리 각 원소 별로 곱셈이 이루어지게 됩니다. \n",
        "\n",
        "그러므로 기본적으로 텐서의 크기가 동일해야 연산이 가능합니다. \n",
        "\n",
        "그러나 텐서의 크기가 다르더라도 텐서의 크기를 암묵적으로 확장하여 계산을 수행하는 경우들이 있는데 이를 **브로드캐스팅**이라고 부릅니다. \n"
      ],
      "metadata": {
        "id": "4kuRwaTlz64Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor([1,2,3])\n",
        "y=torch.tensor([2])\n",
        "print(x.size())\n",
        "print(y.size())\n",
        "print(x*y)"
      ],
      "metadata": {
        "id": "LtCf9XwOz5_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbdcaf9-c82c-43c2-83e1-61361b06a6d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "torch.Size([1])\n",
            "tensor([2, 4, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 예제에서 1X3의 크기를 가진 텐서와 텐서 [2]는 사실상 [2, 2, 2]로 확장되었다. \n",
        "\n",
        "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_1.png\" width=600>"
      ],
      "metadata": {
        "id": "ybz1Llx20Vfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같은 브로드캐스팅은 다음의 조건을 만족할 때, 가능하다. \n",
        "1. 가장 마지막 차원(가장 오른쪽)의 차원이 동일해야 한다.\n",
        "2. 또는 차원의 값이 1이어야 한다. \n",
        "\n",
        "두 개의 텐서는 동일한 차원을 가질 필요는 없다. \n",
        "\n",
        "브로드캐스팅이 일어날 때는 둘 중에 더 큰 차원을 따라가도록 작동한다. \n",
        "\n"
      ],
      "metadata": {
        "id": "6xRKjwlE05jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예를 들어서 크기가 서로 다른 아래의 두 개의 텐서 연산이 일어나면 최종적인 결과물은 아래와 같다. \n",
        "\n",
        "\n",
        "> A      (4d array):  8 x 1 x 6 x 1\n",
        ">\n",
        "> B      (3d array):      7 x 1 x 5\n",
        "> \n",
        "> Result (4d array):  8 x 7 x 6 x 5\n",
        "\n",
        "즉, 차원 값이 1인 차원은 다른 연산의 대상이 되는 텐서의 차원 값을 따라가면서 확장이 일어난다. "
      ],
      "metadata": {
        "id": "FrwVaHB12Asz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[ 0.0,  0.0,  0.0],\n",
        "              [10.0, 10.0, 10.0],\n",
        "              [20.0, 20.0, 20.0],\n",
        "              [30.0, 30.0, 30.0]])\n",
        "b = torch.tensor([1.0, 2.0, 3.0])\n",
        "c = a+b\n",
        "print(a.size())\n",
        "print(b.size())\n",
        "print(c.size())\n",
        "print(c)"
      ],
      "metadata": {
        "id": "vOWt4mdf05CV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8559659-7a98-4ffe-acd5-fff049d67d0d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3])\n",
            "torch.Size([3])\n",
            "torch.Size([4, 3])\n",
            "tensor([[ 1.,  2.,  3.],\n",
            "        [11., 12., 13.],\n",
            "        [21., 22., 23.],\n",
            "        [31., 32., 33.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_2.png\" width=800>\n",
        "\n",
        "1차원 텐서가 2차원 텐서로 확장이 이루어졌다. "
      ],
      "metadata": {
        "id": "N1Oahn4V3Jm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
        "#c = a + b # Error!"
      ],
      "metadata": {
        "id": "3BvufP3V3B_R"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_3.png\" width=600>\n",
        "\n",
        "그러나 마지막 차원의 크기가 맞지 않으면 broadcasting이 이루어지지 않는다. "
      ],
      "metadata": {
        "id": "9AgKoG573TX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 예제 처럼 차원 확장을 통한 계산도 가능하다. \n",
        "\n",
        "np.newaxis는 존재하지 않던 차원을 확장하도록 해주는 기능을 가진다.  "
      ],
      "metadata": {
        "id": "wtIg_H7o3ple"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([0.0, 10.0, 20.0, 30.0])\n",
        "print(\"a:\", a)\n",
        "print(\"a.shape:\", a.shape)\n",
        "\n",
        "b = torch.tensor([1.0, 2.0, 3.0])\n",
        "print(\"b:\", b)\n",
        "print(b.shape)\n",
        "\n",
        "c = a[:, np.newaxis] # [4] -> [4,1] 차원의 2차원 텐서로 변환되었다. \n",
        "print(\"c:\", c)\n",
        "print(c.shape)\n",
        "\n",
        "print(\"c+b:\", c + b) "
      ],
      "metadata": {
        "id": "XF4Xq5C53oc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6216941e-120c-4664-850b-a8bf49117b36"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: tensor([ 0., 10., 20., 30.])\n",
            "a.shape: torch.Size([4])\n",
            "b: tensor([1., 2., 3.])\n",
            "torch.Size([3])\n",
            "c: tensor([[ 0.],\n",
            "        [10.],\n",
            "        [20.],\n",
            "        [30.]])\n",
            "torch.Size([4, 1])\n",
            "c+b: tensor([[ 1.,  2.,  3.],\n",
            "        [11., 12., 13.],\n",
            "        [21., 22., 23.],\n",
            "        [31., 32., 33.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://numpy.org/doc/stable/_images/broadcasting_4.png\" width=600>"
      ],
      "metadata": {
        "id": "J8ei6J7k3g1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 행렬 곱(matrix multiplication)\n",
        "------\n",
        "딥러닝에서 가장 많이 사용되는 연산은 바로 행렬의 곱입니다. \n",
        "\n",
        "많은 경우, 입력 벡터 $\\mathbf{x}$를 받아서 학습된 가중치 행렬 $\\mathbf{W}$를 사용하여 변환되는 경우가 많습니다 \n",
        "\n",
        "행렬 곱셈을 수행하는 여러 가지 함수가 파이토치에서는 구현되어 있다. \n",
        "\n",
        "그 중 일부는 다음과 같습니다:\n",
        "\n",
        "* `torch.matul`: 두 개의 텐서에 대해 행렬 곱을 수행한다. 여기서 특정 동작은 차원에 따라 달라집니다. 두 입력이 모두 행렬(2차원 텐서)인 경우 표준 행렬 곱을 수행한다. 고차원 입력의 경우 이 기능은 브로드캐스트를 지원한다. \n",
        "(자세한 내용은 [manual](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul) 참조). **numpy와 비슷하게 a @ b로도 쓸 수 있다.**\n",
        "* `torch.mm`: 두 개의 행렬에 걸쳐 행렬 곱을 수행하지만 브로드 캐스트 기능은 지원하지 않는다([설명](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm)  참조)\n",
        "* `torch.bmm`: 지원 배치 차원으로 매트릭스 제품을 수행한다. 첫 번째 텐서 $T$가 모양($b\\times n\\times m$)이고 두 번째 텐서 $R$($b\\times m\\times p$)인 경우 출력 $O$는 모양($b\\times n\\times p$)이며 $T$와 $R$의 하위 행렬의 $b$ 행렬 곱셈을 수행한다. \n",
        "* `torch.einsum`: 아인슈타인 합계 규칙을 사용하여 행렬 곱셈 등(즉, 곱셈)을 수행합니다. \n",
        "\n",
        "보통 **torch.matul**이나 **torch.bmm**을 많이 사용합니다. \n",
        "\n",
        "아래의 `torch.matul`을 사용하여 행렬 곱셈을 시도할 수 있습니다."
      ],
      "metadata": {
        "id": "25KOJ-z8wIr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(6)\n",
        "x = x.view(2, 3)\n",
        "print(\"X\\n\", x)"
      ],
      "metadata": {
        "id": "Uit_rcFVvgRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0342cb7-6e76-4550-89a9-b6d2bc7fea93"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X\n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
        "print(\"W\\n\", W)"
      ],
      "metadata": {
        "id": "_kNujiSG4Xa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdafe5e-98b9-4a49-f726-b14225770785"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W\n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
        "print(\"h \\n\", h)"
      ],
      "metadata": {
        "id": "NY9-BsKw4ZaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c231068-24c8-4cd8-cc10-cf68f8a457cd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h \n",
            " tensor([[15, 18, 21],\n",
            "        [42, 54, 66]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 인덱싱(Indexing)\n",
        "\n",
        "일반적인 파이썬의 iterable과 같이 인덱싱이 가능하다. \n",
        " "
      ],
      "metadata": {
        "id": "hYaoxwcu6UPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "9Iy5GfQY4apf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d78120-ca91-422c-f4ac-6b0f0c7e5b5b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:, 1])   # Second column"
      ],
      "metadata": {
        "id": "c630o7UX7Xcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc519d0-675d-4f81-b020-2496c8bf1065"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 5, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0])      # First row"
      ],
      "metadata": {
        "id": "RO2C7B9h7bQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1017560f-9551-4334-abe9-3774296a648c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:2, -1]) # First two rows, last column"
      ],
      "metadata": {
        "id": "fEhfPeXQ7blN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e28e2f8-7cfc-4589-e9a9-1b9a87c859e1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[1:3, :]) # Middle two rows"
      ],
      "metadata": {
        "id": "_uBgaS4k7d6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a34e1b-17bb-4145-eee7-e46161033540"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 퍼셉트론\n",
        "------\n",
        "\n",
        "딥러닝에서 가장 기본이 되는 개념은 퍼셉트론이라고 하는 개념이다. \n",
        "\n",
        "퍼셉트론은 1957년 프랑크 로젠블라트에 의해서 제안되었으며, 초창기에는 아주 간단한 선형 분류만 가능한 모델이었으나 다층 퍼셉트론을 이용하면 더 복잡한 모델을 구성할 수 있다는 것을 발견하였다. \n",
        "\n",
        "퍼셉트론은 신경 세포의 구조를 모사한 것이다. \n",
        "\n"
      ],
      "metadata": {
        "id": "gwMKQzMW9pXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Neuron.svg/800px-Neuron.svg.png\" width=600>"
      ],
      "metadata": {
        "id": "ruxkggBl_FO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.nomidl.com/wp-content/uploads/2022/04/image-5.png\" width=600>\n"
      ],
      "metadata": {
        "id": "4egxLGgL_Or_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적으로 perceptron은 $n$차원의 입력 $x_1$, $x_2$, $x_3$, $\\dots$, $x_n$을 받아서 이 입력의 **선형 결합** $\\sum w_i x_i + b$으로 근사한다. \n",
        "\n",
        "그 후, 선형 결합으로 얻은 값을 **비선형 활성 함수(activation function)**에 한 번 더 통과시켜 최종적인 추정 값을 얻는다. \n",
        "\n",
        "$\\hat{y}=f(\\sum w_i x_i + b)$ \n",
        "\n",
        "여기에서 $f$는 비선형의 활성함수이다. \n",
        "\n",
        "비선형의 활성함수를 이용하는 이유는 선형 결합의 선형 결합을 여러번 취하더라도 그 결과는 선형이기 때문에 선형이 아닌 관계를 추론하기 위해서는 반드시 비선형의 활성함수가 중간에 필요하다. \n",
        "\n"
      ],
      "metadata": {
        "id": "6WDK2cgc_dsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하나의 퍼셉트론이 아니라 여러개의 퍼셉트론을 사용할 경우는 다음과 같이 그림으로 나타낼 수 있다. \n",
        "\n",
        "<img src=\"https://python-course.eu/images/machine-learning/example_network_3_4_2_without_bias.webp\" width=600>"
      ],
      "metadata": {
        "id": "gaFzJt5jAkHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 3차원의 입력을 받아서 4차원의 출력으로 바꾸는 연산은 다음의 행렬 곱으로 나타낼 수 있다. \n",
        "\n",
        "$\n",
        "f\\left[\\begin{pmatrix}\n",
        "x_1\\\\\n",
        "x_2\\\\\n",
        "x_3\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "w_{11} w_{12} w_{13} w_{14} \\\\\n",
        "w_{21} w_{22} w_{23} w_{24} \\\\\n",
        "w_{31} w_{32} w_{33} w_{34} \\\\\n",
        "\\end{pmatrix}\n",
        "+\n",
        "\\begin{pmatrix}\n",
        "b_1\\\\\n",
        "b_2\\\\\n",
        "b_3\\\\\n",
        "b_4\n",
        "\\end{pmatrix}\\right]\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "h_1\\\\\n",
        "h_2\\\\\n",
        "h_3\\\\\n",
        "h_4\\\\\n",
        "\\end{pmatrix}\n",
        "$\n",
        "\n",
        "이 때, $f$는 활성 함수이고, 입력 차원은 3차원이고 숨겨진 차원은 4차원이다. \n",
        "\n"
      ],
      "metadata": {
        "id": "cgKIdRETBn8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://static.javatpoint.com/tutorial/tensorflow/images/single-layer-perceptron-in-tensorflow.png\" width=500>\n",
        "\n"
      ],
      "metadata": {
        "id": "Mueb92vbDtRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "그 후, 최종 출력을 2차원으로 만들기 위해서는 4차원 입력을 2차원으로 바꾸어주는 두 번째 행렬을 곱해주면 된다. \n",
        "\n",
        "$\\mathbf{O} = \\mathbf{h}\\mathbf{W_2} + \\mathbf{b_2}$\n",
        "\n",
        "이 때, $\\mathbf{W_2}$의 형태는 $4 × 2$가 되어 4차원의 벡터를 2차원으로 변환시켜 준다. \n",
        "\n",
        "즉, 이렇게 여러개의 perceptron을 여러 층으로 쌓은 경우를 multi-layer perceptron(MLP)라고 부른다. \n",
        "\n",
        "그리고 multilayer perceptron은 결국 여러 층의 **파라미터 행렬**의 연산을 계속 수행하는 것이라고 이해할 수 있다. \n",
        "\n",
        "다시 말해, 입력 텐서의 차원이 $N$차원이고 이를 $M$차원의 출력으로 바꾸어 주는 perceptron layer는 $N \\times M$ 의 크기를 가지는 **행렬곱**에 해당한다. \n",
        "\n",
        "우리가 **학습**이라고 부르는 것은 원하는 목적 값(objective value)를 정확하게 예측하는 **파라미터들**, 또는 **가중치**라고도 부름, ($w_i$ 값)을 찾아내는 것이라고 할 수 있다. \n"
      ],
      "metadata": {
        "id": "q6slzTF4DUu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/publication/334609713/figure/fig1/AS:783455927406593@1563801857102/Multi-Layer-Perceptron-MLP-diagram-with-four-hidden-layers-and-a-collection-of-single_Q640.jpg\" width=600>"
      ],
      "metadata": {
        "id": "EgPjdJTDECpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "딥러닝이라는 이름이 명명된 이유는 불과 20여년전의 인공 지능 모델만 하더라도 컴퓨터 메모리의 한계와 계산 속도의 한계로 인해서 hidden layer를 몇 층 정도만을 쌓을 수 있었다. \n",
        "\n",
        "그러나 GPU를 이용한 계산과 컴퓨터 메모리의 발전에 의해서 최근에는 수십, 수백층 까지의 layer를 쌓을 수 있게 되었다. \n",
        "\n",
        "그리고 이와 같이 매우 깊이 층을 쌓았을 때, 많은 문제에서 기존의 몇 개의 층을 쌓은 문제에 비해서 훨씬 정확한 결과를 얻을 수 있다는 것을 발견하였다. \n",
        "\n"
      ],
      "metadata": {
        "id": "6_vBOjTYEq97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음의 그래프는 image를 분류하는 ImageNet challenge의 정확도 향상을 보여준다. \n",
        "\n",
        "<img src=\"https://blog.roboflow.com/content/images/2021/06/image-18.png\" width=600>"
      ],
      "metadata": {
        "id": "h0Q_FY75FaUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://www.researchgate.net/publication/332452649/figure/fig1/AS:770098897887234@1560617293964/Error-rates-on-the-ImageNet-Large-Scale-Visual-Recognition-Challenge-Accuracy.ppm\" width=600>\n",
        "\n",
        "딥러닝 방법이 처음 제안된 2012년부터 에러율이 급격히 낮아짐을 확인할 수 있다. \n",
        "\n",
        "2015년부터는 인간의 에러율을 넘어서는 성능을 보여주고 있다. "
      ],
      "metadata": {
        "id": "91XWG8ToFK3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 얻어진 최종적인 output 값을 원하는 true 값과 비교를 통해 손실 함수($L$)를 계산한다. \n",
        "\n",
        "얻어진 손실 함수의 값을 **최소화**하는 방향으로 파라미터들이 업데이트 된다. \n",
        "\n",
        "이를 수식으로 표현하면 다음과 같다. "
      ],
      "metadata": {
        "id": "l5lDYdHmEn8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$w_{i,\\mathrm{new}} = w_{i,\\mathrm{old}} - \\eta \\frac{\\partial L}{\\partial w_i}$"
      ],
      "metadata": {
        "id": "IhfqxyuvHknO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 계산 그래프와 역전파\n",
        "---------\n",
        "\n",
        "딥러닝이 폭발적으로 발전할 수 있었던 중요한 계기 중의 하나는 복잡한 손실 함수의 기울기를 빠르게 계산하여 파라미터를 효율적으로 업데이트 할 수 있었기 때문입니다. \n",
        "\n",
        "파이토치에서는 어떤 연산을 수행하면 내부적으로 연산에 참여한 모든 변수에 대한 기울기를 계산할 수 있는 기능을 가지고 있습니다. \n",
        "\n",
        "이는 계산 그래프와 역전파를 통해서 이루어집니다. \n",
        "\n",
        "다음의 예시를 봅시다. "
      ],
      "metadata": {
        "id": "gZJwGnP97tMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones((3,))\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "3E8UKUGR7fai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5993552e-0448-4b1b-a94b-1c792036ef60"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적으로 텐서를 생성하면 gradient를 계산하지 않도록 초기화 됩니다. "
      ],
      "metadata": {
        "id": "3EZDITz0IWgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)"
      ],
      "metadata": {
        "id": "-ZKkgOYTITU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18088c2a-333d-431f-ee95-c28c5aaf10f1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 requires_grad_라는 method를 실행하면 주어진 텐서의 기울기를 계산하도록 설정되게 됩니다. "
      ],
      "metadata": {
        "id": "vmz3bzW_Ib4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "계산 그래프의 개념과 익숙해지기 위해서 다음의 함수를 생각해봅시다. \n",
        "\n",
        "$$y = \\frac{1}{|x|}\\sum_i \\left[(x_i + 2)^2 + 3\\right]$$\n",
        "\n",
        "위 식에서 $x$가 파라미터이고, 목적 값인 $y$를 최소화 또는 최대화 하는 것이 우리의 목표입니다. \n",
        "\n",
        "이를 위해서 $y$에 대한 편미분을 계산해야 합니다: $\\partial y / \\partial \\mathbf{x}$. \n",
        "\n",
        "본 예시에서는 $\\mathbf{x}=[0,1,2]$ 를 입력 값으로 사용합니다. "
      ],
      "metadata": {
        "id": "gvin5V0sIjPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3, dtype=torch.float32, requires_grad=True) # Only float tensors can have gradients\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "fRU4ntwbIUoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee4dc62-59df-481c-b308-6b2e468a8824"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([0., 1., 2.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 함수 값을 얻기 위한 연산을 단계별로 나누어 보면 다음과 같이 쓸 수 있습니다. "
      ],
      "metadata": {
        "id": "Bk7LjNyXJKVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = x + 2\n",
        "b = a ** 2\n",
        "c = b + 3\n",
        "y = c.mean()\n",
        "print(\"Y\", y)"
      ],
      "metadata": {
        "id": "yBRPOTZrJG2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d58bf13-7c40-4f4b-f884-7ab8bf2fbccc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y tensor(12.6667, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 위의 연산을 그래프로 나타내면 아래와 같습니다. "
      ],
      "metadata": {
        "id": "iD22KyHLJcxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/pytorch_computation_graph.svg?raw=1\" width=200>\n",
        "\n",
        "각 화살표는 하나의 연산에 해당합니다. \n",
        "\n",
        "이 때, 각 연산에 해당하는 미분 값을 빠르게 구할 수 있습니다. \n",
        "\n",
        "각 단계의 미분 값을 얻으면 이를 chain rule을 이용해서 연결하면, 최종적으로 우리가 원하는 변수의 기울기 값을 구할 수 있습니다. \n",
        "\n",
        "그렇기 때문에 최종적인 목적 함수 값 $y$에서 역으로 따라가면서 입력 값 $x$에 대한 미분 값을 얻게 되기 때문에 이를 backpropagation이라고 부릅니다. "
      ],
      "metadata": {
        "id": "_y_z_IwZJXLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "backpropagation은 다음의 명령을 통해서 수행됩니다. "
      ],
      "metadata": {
        "id": "rIQCC3KtKgOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "jmF203_TKjke"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`x.grad` \b는 이제 $\\partial y/ \\partial \\mathcal{x}$ 값을 저장하게 됩니다. \n",
        "\n",
        "이 값은 입력 값인 $\\mathbf{x}=[0,1,2]$에서 $y$ 값의 변화량을 나타내게 됩니다. "
      ],
      "metadata": {
        "id": "XxhQ0vvwKllE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)"
      ],
      "metadata": {
        "id": "Hs0S4l2bK5qb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92884e4e-f0ee-4458-c67a-3b5d9b85a4a8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3333, 2.0000, 2.6667])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 역전파를 수식으로 나타내면 다음과 같습니다. \n",
        "\n",
        "$$\\frac{\\partial y}{\\partial x_i} = \\frac{\\partial y}{\\partial c_i}\\frac{\\partial c_i}{\\partial b_i}\\frac{\\partial b_i}{\\partial a_i}\\frac{\\partial a_i}{\\partial x_i}$$"
      ],
      "metadata": {
        "id": "Y-K7Lkc9J-Ru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we have simplified this equation to index notation, and by using the fact that all operation besides the mean do not combine the elements in the tensor. The partial derivatives are:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial a_i}{\\partial x_i} = 1,\\hspace{1cm}\n",
        "\\frac{\\partial b_i}{\\partial a_i} = 2\\cdot a_i\\hspace{1cm}\n",
        "\\frac{\\partial c_i}{\\partial b_i} = 1\\hspace{1cm}\n",
        "\\frac{\\partial y}{\\partial c_i} = \\frac{1}{3}\n",
        "$$\n",
        "\n",
        "Hence, with the input being $\\mathbf{x}=[0,1,2]$, our gradients are $\\partial y/\\partial \\mathbf{x}=[4/3,2,8/3]$. The previous code cell should have printed the same result."
      ],
      "metadata": {
        "id": "zVCn2qOWKcZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU support\n",
        "------\n",
        "앞서 논의 했듯이 GPU를 이용한 계산이 딥러닝의 발전에 매우 중요한 역할을 하였습니다. \n",
        "\n",
        "GPU의 경우, 매우 단순한 연산(덧셈, 곱셈)을 평행하게 처리하는데 특화되어 있어서 특정 계산에 있어서는 CPU에 비해서 훨씬 빠른 성능을 보여줍니다. \n",
        "\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/comparison_CPU_GPU.png?raw=1\" width=\"700px\"></center>"
      ],
      "metadata": {
        "id": "FXRhPS4jLBZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 cell을 실행하면 여러분의 현재 colab 세션에서 GPU를 사용가능한지 보여줍니다. "
      ],
      "metadata": {
        "id": "MQbK09X2LneF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "_jiw8ibNJJ4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3abe551-43ce-4494-a6e5-a553d3b42816"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://devsoyoung.github.io/static/874712e6233d2209010f47e7229ff3d2/4f5bc/runtime.webp\" width=500>\n"
      ],
      "metadata": {
        "id": "LqYzhiQHLwTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://t1.daumcdn.net/cfile/tistory/99924D345B435A7003\" width=600>"
      ],
      "metadata": {
        "id": "brTJYcwKMVaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 하드웨어 가속기를 GPU로 설정하면 gpu를 사용하실 수 있습니다. "
      ],
      "metadata": {
        "id": "-s06fFRwMkfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "eaX9H0daLv27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14439eae-d283-4e2a-c080-bdd438935457"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the GPU available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "현재 할당된 GPU의 spec을 확인해봅시다. "
      ],
      "metadata": {
        "id": "GP7A-IT21frt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "8oz9-5of0qsu",
        "outputId": "6a66e56b-2c86-48b7-b132-833ec27baa6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-49811958-d3cd-5881-0121-39195777e9bc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "cWi06J5Y1kB-",
        "outputId": "de8f32bb-76ea-4e15-8047-8bc5b1830a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar 28 02:23:21 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    11W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적으로 텐서가 정의되면 CPU에서 계산이 되게 되어 있습니다. \n",
        "\n",
        "텐서의 값이 GPU에서 계산되도록 하려면 `.to(...)`, 또는 `.cuda()` 함수를 이용해서 GPU에서 계산이 수행되도록 할 수 있습니다. \n",
        "\n",
        "또는 아래와 같이 `.device()` method를 이용해서 계산이 수행되는 플랫폼을 지정할 수 있습니다. "
      ],
      "metadata": {
        "id": "Ordf3yDbM9pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "TwssdwKzMxHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5424a6e8-0d40-4d57-a79b-08faa69afdc0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드를 이용하면 텐서를 선언하고 GPU에서 계산이 되도록 할 수 있다. "
      ],
      "metadata": {
        "id": "n06s_wHJNjrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 3)\n",
        "x = x.to(device)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "ECmedTnhNi8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec709df-da8c-4d1e-9e12-d289b001d3e5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음의 코드를 실행시키면 CPU와 GPU의 행렬 곱셈 연산에서의 속도 차이를 알 수 있다. "
      ],
      "metadata": {
        "id": "pqqhfdMYNiua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "## CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "## GPU version\n",
        "x = x.to(device)\n",
        "#_ = torch.matmul(x, x)  # First operation to 'burn in' GPU\n",
        "# CUDA is asynchronous, so we need to use different timing functions\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "_ = torch.matmul(x, x)\n",
        "end.record()\n",
        "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
      ],
      "metadata": {
        "id": "VDf0ogEaN3s_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32aa7850-4bbd-4cf2-932e-2fdf1f282f82"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU time: 3.35827s\n",
            "GPU time: 1.16899s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파이토치 기반의 multilayer perceptron 모델을 이용한 분자 독성 예측\n",
        "-------"
      ],
      "metadata": {
        "id": "yr6PKNdfOV2q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn 모듈\n",
        "-------\n",
        "`torch.nn` \b모듈에서는 기본적인 딥러닝 훈련을 위해서 필요한 대부분의 함수들이 구현되어 있습니다. \n",
        "전체 `torch.nn` \b모듈의 함수 리스트는 다음 [링크](https://pytorch.org/docs/stable/nn.html) 에서 확인 할 수 있습니다. 많은 레이어들이 이미 구현되어 있으므로 torch.nn의 문서를 잘 읽어보시는 것이 도움이 될 것입니다. "
      ],
      "metadata": {
        "id": "BocfKec3GkCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "cy5OKjX_HA_y"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "또한 많은 유용한 함수들이 `torch.nn.functional` 모듈 아래에 구현되어 있습니다.\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.functional.html"
      ],
      "metadata": {
        "id": "41eZR2gcHIAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "2wB29m9lHWyV"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### nn.Module\n",
        "\n",
        "파이토치에서 신경망 모델은 nn.Module을 기본으로 하여 작성된다. \n",
        "\n",
        "즉, nn.Module은 모든 파이토치 신경망 모델의 기본 Base class가 된다고 할 수 있다. \n",
        "\n",
        "대부분의 파이토치를 이용해서 작성한 신경망 모델은 nn.Module을 상속 받아서 작성된다고 생각하면 된다. "
      ],
      "metadata": {
        "id": "geIA0zphHZRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본적인 파이토치의 신경망 모델은 다음과 같은 구조를 가진다. \n",
        "\n",
        "처음 신경망이 생성될 때 실행될 **\\_\\_init\\_\\_** 함수와 입력 텐서가 들어왔을 때 손실 함수를 계산하게 될 **foward** method를 정의해주어야 한다. "
      ],
      "metadata": {
        "id": "1e63ArqfIIuc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "일반적으로 **\\_\\_init\\_\\_** 에서는 신경망을 구성하는 레이어들을 선언하게 된다. \n",
        "\n",
        "그리고 forward 함수에서는 텐서가 어떤 순서로 계산되는지를 정의하게 된다. "
      ],
      "metadata": {
        "id": "EwXXxjfJIt65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModule(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Some init for my module\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Function for performing the calculation of the module.\n",
        "        pass"
      ],
      "metadata": {
        "id": "g2P2YXpYIFEJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MLP 기반의 classification model\n",
        "\n",
        "연습을 위해서 hidden layer가 하나이고 tanh 함수를 activation 함수로 사용하는 간단한 classifier를 정의해보자. \n",
        "\n",
        "<img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/small_neural_network.svg?raw=1\" width=400>"
      ],
      "metadata": {
        "id": "GvclGBK3I7TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        super().__init__()\n",
        "        # 네트워크를 구성하는 위한 기반이 되는 layer들을 정의한다. \n",
        "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.act_fn = nn.Tanh()\n",
        "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.linear1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RkTX5wHHJThI"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "만일 위의 그림과 같이 입력 텐서의 차원이 2이고, 숨겨진 차원이 4, 출력 차원이 2라면 다음과 같이 모델을 초기화 할 수 있다. "
      ],
      "metadata": {
        "id": "UgIWwn95KaFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=2)"
      ],
      "metadata": {
        "id": "SEsVl0PQK4-Y"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdgP-9g3LBKC",
        "outputId": "29e5a30a-83eb-47c6-a660-0bdea1ac20e7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleClassifier(\n",
            "  (linear1): Linear(in_features=2, out_features=4, bias=True)\n",
            "  (act_fn): Tanh()\n",
            "  (linear2): Linear(in_features=4, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "신경망을 구성하는 모든 서브 모듈, 레이어들의 파라미터들을 확인하기 위해서는 `parameters()` 또는 `named_parameters()` 함수를 이용하여 출력할 수 있다. "
      ],
      "metadata": {
        "id": "GkqZvY6dLM1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(f\"Parameter {name}, shape {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syIIOpx0L-7w",
        "outputId": "cbef665e-4cb5-43be-fe75-c3c8486096bf"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter linear1.weight, shape torch.Size([4, 2])\n",
            "Parameter linear1.bias, shape torch.Size([4])\n",
            "Parameter linear2.weight, shape torch.Size([2, 4])\n",
            "Parameter linear2.bias, shape torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 layer는 $4\\times2$, $2\\times4$ 형태를 가지는 파라미터 행렬로 이루어져 있음을 알 수 있다. \n",
        "\n",
        "각 layer의 bias 값은 output 텐서의 크기와 동일하다. \n",
        "\n",
        "tanh 함수는 학습 가능한 파라미터를 가지고 있지 않다. \n",
        "\n",
        "그리고 기본적으로 모든 layer들은 class의 직접적인 attribute로 정의되는 것, `self.a = ...`이 추천되는 정의 방법이다. "
      ],
      "metadata": {
        "id": "vvmDBYjyMB1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋\n",
        "------"
      ],
      "metadata": {
        "id": "BU4BICtPNKDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 MLP 모델을 이용해서 분자의 독성을 예측하는 예제를 수행해봅시다. \n",
        "\n",
        "이번 실습에서 사용할 데이터는 Tox21 데이터입니다. \n",
        "\n",
        "Tox21은 미국 NIH에서 관리하는 독성 데이터베이스입니다. \n",
        "https://tripod.nih.gov/tox/\n",
        "\n",
        "지난 2014년 tox21에서 가지고 있는 다양한 receptor들의 독성 데이터를 바탕으로 독성을 예측하는 머신러닝 모델 비교 challenge를 개최하였습니다. \n",
        "\n",
        "https://tripod.nih.gov/tox21/challenge/\n",
        "\n",
        "그 당시 상위권에 입상한 예측 방법들과 결과들은 아래 링크에서 확인할 수 있습니다.\n",
        " \n",
        "https://www.frontiersin.org/research-topics/2954/tox21-challenge-to-build-predictive-models-of-nuclear-receptor-and-stress-response-pathways-as-mediated-by-exposure-to-environmental-toxicants-and-drugs#articles\n",
        "\n",
        "Tox21 데이터는 12개의 타겟에 대한 독성 정보를 담고 있으며, 다양한 머신 러닝 알고리즘들이 얼마나 효과적인지 벤치마크를 하는데 많이 사용되는 표준적인 dataset이 되고 있습니다.  \n"
      ],
      "metadata": {
        "id": "YlsOfOxRNfDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터셋 준비\n",
        "\n",
        "이번 실습에서는 ECFP4 fingerprint를 이용해서 분자의 독성을 예측하는 모델을 만들 예정입니다. \n",
        "\n",
        "우선 fingerprint 준비 과정을 살펴보도록 합시다. "
      ],
      "metadata": {
        "id": "nxzz-Xhb4KIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RDKit을 설치해줍니다. "
      ],
      "metadata": {
        "id": "L85eGGilBfD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czUCoHOoBdfI",
        "outputId": "1bd6b344-009e-4ea7-81a6-432f4160d537"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.9/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rdkit) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from rdkit) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "필요한 모듈을 읽어들입니다. "
      ],
      "metadata": {
        "id": "eLGCCcko5GYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import rdkit\n",
        "import rdkit.Chem as Chem"
      ],
      "metadata": {
        "id": "n3WCg90RAcW8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Tox21 data를 온라인 링크로 부터 바로 읽어들입니다. pandas의 read_csv는 압축된 csv 파일을 자동으로 압축을 풀어서 읽을 수 있습니다. "
      ],
      "metadata": {
        "id": "7rcQqlxCBSQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " df = pd.read_csv('https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/tox21.csv.gz')"
      ],
      "metadata": {
        "id": "mMqlEhZx47zJ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "또는 파일을 다운로드 받아서 읽어들일 수 있습니다. "
      ],
      "metadata": {
        "id": "HlDwwyul5XTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O tox21.csv.gz https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/tox21.csv.gz\n",
        "df = pd.read_csv('tox21.csv.gz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN5vTggK_1vR",
        "outputId": "b8986657-ff8c-4562-b8ec-d5a809cafe32"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-28 02:23:37--  https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/tox21.csv.gz\n",
            "Resolving deepchemdata.s3-us-west-1.amazonaws.com (deepchemdata.s3-us-west-1.amazonaws.com)... 3.5.160.124\n",
            "Connecting to deepchemdata.s3-us-west-1.amazonaws.com (deepchemdata.s3-us-west-1.amazonaws.com)|3.5.160.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 122925 (120K) [application/x-gzip]\n",
            "Saving to: ‘tox21.csv.gz’\n",
            "\n",
            "tox21.csv.gz        100%[===================>] 120.04K   338KB/s    in 0.4s    \n",
            "\n",
            "2023-03-28 02:23:38 (338 KB/s) - ‘tox21.csv.gz’ saved [122925/122925]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wYHOX-D0BmWq",
        "outputId": "be742bba-566c-4b75-b7ba-5daa1ed3bdc2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      NR-AR  NR-AR-LBD  NR-AhR  NR-Aromatase  NR-ER  NR-ER-LBD  NR-PPAR-gamma  \\\n",
              "0       0.0        0.0     1.0           NaN    NaN        0.0            0.0   \n",
              "1       0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
              "2       NaN        NaN     NaN           NaN    NaN        NaN            NaN   \n",
              "3       0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
              "4       0.0        0.0     0.0           0.0    0.0        0.0            0.0   \n",
              "...     ...        ...     ...           ...    ...        ...            ...   \n",
              "7826    NaN        NaN     NaN           NaN    NaN        NaN            NaN   \n",
              "7827    1.0        1.0     0.0           0.0    1.0        0.0            NaN   \n",
              "7828    1.0        1.0     0.0           0.0    1.0        1.0            0.0   \n",
              "7829    1.0        1.0     0.0           NaN    1.0        1.0            0.0   \n",
              "7830    0.0        0.0     NaN           0.0    0.0        0.0            0.0   \n",
              "\n",
              "      SR-ARE  SR-ATAD5  SR-HSE  SR-MMP  SR-p53    mol_id  \\\n",
              "0        1.0       0.0     0.0     0.0     0.0   TOX3021   \n",
              "1        NaN       0.0     NaN     0.0     0.0   TOX3020   \n",
              "2        0.0       NaN     0.0     NaN     NaN   TOX3024   \n",
              "3        NaN       0.0     NaN     0.0     0.0   TOX3027   \n",
              "4        0.0       0.0     0.0     0.0     0.0  TOX20800   \n",
              "...      ...       ...     ...     ...     ...       ...   \n",
              "7826     0.0       NaN     0.0     NaN     NaN   TOX2725   \n",
              "7827     NaN       0.0     0.0     NaN     0.0   TOX2370   \n",
              "7828     1.0       0.0     0.0     0.0     0.0   TOX2371   \n",
              "7829     0.0       0.0     0.0     1.0     1.0   TOX2377   \n",
              "7830     0.0       0.0     0.0     1.0     0.0   TOX2724   \n",
              "\n",
              "                                                 smiles  \n",
              "0                          CCOc1ccc2nc(S(N)(=O)=O)sc2c1  \n",
              "1                             CCN1C(=O)NC(c2ccccc2)C1=O  \n",
              "2     CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...  \n",
              "3                       CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C  \n",
              "4                             CC(O)(P(=O)(O)O)P(=O)(O)O  \n",
              "...                                                 ...  \n",
              "7826  CCOc1nc2cccc(C(=O)O)c2n1Cc1ccc(-c2ccccc2-c2nnn...  \n",
              "7827  CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...  \n",
              "7828  C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...  \n",
              "7829  C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...  \n",
              "7830            COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4  \n",
              "\n",
              "[7831 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a9cafa3-f39c-4ce4-9b10-76c367f91b05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NR-AR</th>\n",
              "      <th>NR-AR-LBD</th>\n",
              "      <th>NR-AhR</th>\n",
              "      <th>NR-Aromatase</th>\n",
              "      <th>NR-ER</th>\n",
              "      <th>NR-ER-LBD</th>\n",
              "      <th>NR-PPAR-gamma</th>\n",
              "      <th>SR-ARE</th>\n",
              "      <th>SR-ATAD5</th>\n",
              "      <th>SR-HSE</th>\n",
              "      <th>SR-MMP</th>\n",
              "      <th>SR-p53</th>\n",
              "      <th>mol_id</th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TOX3021</td>\n",
              "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TOX3020</td>\n",
              "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TOX3024</td>\n",
              "      <td>CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TOX3027</td>\n",
              "      <td>CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TOX20800</td>\n",
              "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7826</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TOX2725</td>\n",
              "      <td>CCOc1nc2cccc(C(=O)O)c2n1Cc1ccc(-c2ccccc2-c2nnn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7827</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TOX2370</td>\n",
              "      <td>CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7828</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TOX2371</td>\n",
              "      <td>C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7829</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>TOX2377</td>\n",
              "      <td>C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7830</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TOX2724</td>\n",
              "      <td>COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7831 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a9cafa3-f39c-4ce4-9b10-76c367f91b05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a9cafa3-f39c-4ce4-9b10-76c367f91b05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a9cafa3-f39c-4ce4-9b10-76c367f91b05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7831개의 분자들의 12개의 타겟에 대한 독성 값을 가지고 있습니다. "
      ],
      "metadata": {
        "id": "S_VRuh2b5Ruz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "PfRX_VtkDT8T",
        "outputId": "3cf5c3ec-813d-48b0-bbd8-182724d45acc"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             NR-AR    NR-AR-LBD       NR-AhR  NR-Aromatase        NR-ER  \\\n",
              "count  7265.000000  6758.000000  6549.000000   5821.000000  6193.000000   \n",
              "mean      0.042533     0.035070     0.117270      0.051538     0.128048   \n",
              "std       0.201815     0.183969     0.321766      0.221110     0.334170   \n",
              "min       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000      0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000      1.000000     1.000000   \n",
              "\n",
              "         NR-ER-LBD  NR-PPAR-gamma       SR-ARE     SR-ATAD5       SR-HSE  \\\n",
              "count  6955.000000    6450.000000  5832.000000  7072.000000  6467.000000   \n",
              "mean      0.050324       0.028837     0.161523     0.037330     0.057523   \n",
              "std       0.218627       0.167362     0.368044     0.189583     0.232857   \n",
              "min       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "            SR-MMP       SR-p53  \n",
              "count  5810.000000  6774.000000  \n",
              "mean      0.158003     0.062445  \n",
              "std       0.364776     0.241979  \n",
              "min       0.000000     0.000000  \n",
              "25%       0.000000     0.000000  \n",
              "50%       0.000000     0.000000  \n",
              "75%       0.000000     0.000000  \n",
              "max       1.000000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0127880-faae-4e97-866a-7bf24268e905\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NR-AR</th>\n",
              "      <th>NR-AR-LBD</th>\n",
              "      <th>NR-AhR</th>\n",
              "      <th>NR-Aromatase</th>\n",
              "      <th>NR-ER</th>\n",
              "      <th>NR-ER-LBD</th>\n",
              "      <th>NR-PPAR-gamma</th>\n",
              "      <th>SR-ARE</th>\n",
              "      <th>SR-ATAD5</th>\n",
              "      <th>SR-HSE</th>\n",
              "      <th>SR-MMP</th>\n",
              "      <th>SR-p53</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7265.000000</td>\n",
              "      <td>6758.000000</td>\n",
              "      <td>6549.000000</td>\n",
              "      <td>5821.000000</td>\n",
              "      <td>6193.000000</td>\n",
              "      <td>6955.000000</td>\n",
              "      <td>6450.000000</td>\n",
              "      <td>5832.000000</td>\n",
              "      <td>7072.000000</td>\n",
              "      <td>6467.000000</td>\n",
              "      <td>5810.000000</td>\n",
              "      <td>6774.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.042533</td>\n",
              "      <td>0.035070</td>\n",
              "      <td>0.117270</td>\n",
              "      <td>0.051538</td>\n",
              "      <td>0.128048</td>\n",
              "      <td>0.050324</td>\n",
              "      <td>0.028837</td>\n",
              "      <td>0.161523</td>\n",
              "      <td>0.037330</td>\n",
              "      <td>0.057523</td>\n",
              "      <td>0.158003</td>\n",
              "      <td>0.062445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.201815</td>\n",
              "      <td>0.183969</td>\n",
              "      <td>0.321766</td>\n",
              "      <td>0.221110</td>\n",
              "      <td>0.334170</td>\n",
              "      <td>0.218627</td>\n",
              "      <td>0.167362</td>\n",
              "      <td>0.368044</td>\n",
              "      <td>0.189583</td>\n",
              "      <td>0.232857</td>\n",
              "      <td>0.364776</td>\n",
              "      <td>0.241979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0127880-faae-4e97-866a-7bf24268e905')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0127880-faae-4e97-866a-7bf24268e905 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0127880-faae-4e97-866a-7bf24268e905');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 실습에서는 Neclear receptor-Androgen receptor (NR-AR) 타겟에 대한 독성 예측을 수행해 봅시다. "
      ],
      "metadata": {
        "id": "I43hcm4qDRF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub=df[[\"NR-AR\", \"smiles\"]].copy()"
      ],
      "metadata": {
        "id": "pA5njajOEGGw"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YmX1_3yPEJJ5",
        "outputId": "01ecd849-6f4e-45e6-e369-e54c8b9d04c4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      NR-AR                                             smiles\n",
              "0       0.0                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1\n",
              "1       0.0                          CCN1C(=O)NC(c2ccccc2)C1=O\n",
              "2       NaN  CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...\n",
              "3       0.0                    CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C\n",
              "4       0.0                          CC(O)(P(=O)(O)O)P(=O)(O)O\n",
              "...     ...                                                ...\n",
              "7826    NaN  CCOc1nc2cccc(C(=O)O)c2n1Cc1ccc(-c2ccccc2-c2nnn...\n",
              "7827    1.0  CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...\n",
              "7828    1.0  C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...\n",
              "7829    1.0  C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...\n",
              "7830    0.0            COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4\n",
              "\n",
              "[7831 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81201b76-1dca-429f-8b96-f3c1c11da7cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NR-AR</th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>CC[C@]1(O)CC[C@H]2[C@@H]3CCC4=CCCC[C@@H]4[C@H]...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7826</th>\n",
              "      <td>NaN</td>\n",
              "      <td>CCOc1nc2cccc(C(=O)O)c2n1Cc1ccc(-c2ccccc2-c2nnn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7827</th>\n",
              "      <td>1.0</td>\n",
              "      <td>CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7828</th>\n",
              "      <td>1.0</td>\n",
              "      <td>C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7829</th>\n",
              "      <td>1.0</td>\n",
              "      <td>C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7830</th>\n",
              "      <td>0.0</td>\n",
              "      <td>COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7831 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81201b76-1dca-429f-8b96-f3c1c11da7cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81201b76-1dca-429f-8b96-f3c1c11da7cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81201b76-1dca-429f-8b96-f3c1c11da7cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "독성 데이터가 NaN (Not a Number)인 경우들을 dropna method를 이용하여 제거하도록 합니다. "
      ],
      "metadata": {
        "id": "pFxk5zBVEOo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.dropna(axis='index', subset='NR-AR', inplace=True)"
      ],
      "metadata": {
        "id": "fkSfi8K_Bm7t"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub"
      ],
      "metadata": {
        "id": "Fw0wYPX66ns5",
        "outputId": "67607ce3-3b0a-4c31-85cd-b0b0643d2fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      NR-AR                                             smiles\n",
              "0       0.0                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1\n",
              "1       0.0                          CCN1C(=O)NC(c2ccccc2)C1=O\n",
              "3       0.0                    CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C\n",
              "4       0.0                          CC(O)(P(=O)(O)O)P(=O)(O)O\n",
              "5       0.0               CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C\n",
              "...     ...                                                ...\n",
              "7825    0.0                 CCCNCC(O)COc1ccccc1C(=O)CCc1ccccc1\n",
              "7827    1.0  CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...\n",
              "7828    1.0  C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...\n",
              "7829    1.0  C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...\n",
              "7830    0.0            COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4\n",
              "\n",
              "[7265 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a866cfc4-f8a3-4447-b007-f55c5a7b80c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NR-AR</th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7825</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCCNCC(O)COc1ccccc1C(=O)CCc1ccccc1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7827</th>\n",
              "      <td>1.0</td>\n",
              "      <td>CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7828</th>\n",
              "      <td>1.0</td>\n",
              "      <td>C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7829</th>\n",
              "      <td>1.0</td>\n",
              "      <td>C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7830</th>\n",
              "      <td>0.0</td>\n",
              "      <td>COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7265 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a866cfc4-f8a3-4447-b007-f55c5a7b80c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a866cfc4-f8a3-4447-b007-f55c5a7b80c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a866cfc4-f8a3-4447-b007-f55c5a7b80c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "wQ9yMEAU7Dxs",
        "outputId": "1f5b61be-3792-498d-e7ab-be9137a49118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      NR-AR                                             smiles\n",
              "0       0.0                       CCOc1ccc2nc(S(N)(=O)=O)sc2c1\n",
              "1       0.0                          CCN1C(=O)NC(c2ccccc2)C1=O\n",
              "2       0.0                    CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C\n",
              "3       0.0                          CC(O)(P(=O)(O)O)P(=O)(O)O\n",
              "4       0.0               CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C\n",
              "...     ...                                                ...\n",
              "7260    0.0                 CCCNCC(O)COc1ccccc1C(=O)CCc1ccccc1\n",
              "7261    1.0  CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...\n",
              "7262    1.0  C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...\n",
              "7263    1.0  C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...\n",
              "7264    0.0            COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4\n",
              "\n",
              "[7265 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef2487e3-d6ed-43fc-bcf2-f093ac3f4cac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NR-AR</th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCOc1ccc2nc(S(N)(=O)=O)sc2c1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCN1C(=O)NC(c2ccccc2)C1=O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCCN(CC)C(CC)C(=O)Nc1c(C)cccc1C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CC(O)(P(=O)(O)O)P(=O)(O)O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7260</th>\n",
              "      <td>0.0</td>\n",
              "      <td>CCCNCC(O)COc1ccccc1C(=O)CCc1ccccc1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7261</th>\n",
              "      <td>1.0</td>\n",
              "      <td>CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7262</th>\n",
              "      <td>1.0</td>\n",
              "      <td>C[C@]12CC[C@H]3[C@@H](CCC4=CC(=O)CC[C@@]43C)[C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>1.0</td>\n",
              "      <td>C[C@]12CC[C@@H]3c4ccc(O)cc4CC[C@H]3[C@@H]1CC[C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7264</th>\n",
              "      <td>0.0</td>\n",
              "      <td>COc1ccc2c(c1OC)CN1CCc3cc4c(cc3C1C2)OCO4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7265 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef2487e3-d6ed-43fc-bcf2-f093ac3f4cac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef2487e3-d6ed-43fc-bcf2-f093ac3f4cac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef2487e3-d6ed-43fc-bcf2-f093ac3f4cac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub.describe()"
      ],
      "metadata": {
        "id": "n0NwkZNJ9rmD",
        "outputId": "b44fb23b-af75-4c07-c737-82b9974717d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             NR-AR\n",
              "count  7265.000000\n",
              "mean      0.042533\n",
              "std       0.201815\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%       0.000000\n",
              "75%       0.000000\n",
              "max       1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9ecac9a-8b10-459b-8b4c-7a6e966a2ab3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NR-AR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7265.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.042533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.201815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9ecac9a-8b10-459b-8b4c-7a6e966a2ab3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9ecac9a-8b10-459b-8b4c-7a6e966a2ab3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9ecac9a-8b10-459b-8b4c-7a6e966a2ab3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 실습에서는 smiles를 ECFP4 fingerprint로 변환한 후, input feature로 사용합니다. "
      ],
      "metadata": {
        "id": "ulXkywM1E2Vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "fp_list = []\n",
        "for smi in tqdm(df_sub[\"smiles\"]):\n",
        "  m = Chem.MolFromSmiles(smi)\n",
        "  fp = AllChem.GetMorganFingerprintAsBitVect(m,2,nBits=1024)\n",
        "  fp_list.append(fp.ToList())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_MxbQ52B6e8",
        "outputId": "54ae9a24-221f-4670-baf9-f0a85c3b03d9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/7265 [00:00<?, ?it/s][02:23:38] WARNING: not removing hydrogen atom without neighbors\n",
            "100%|██████████| 7265/7265 [00:01<00:00, 4719.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp_df = pd.DataFrame(fp_list)"
      ],
      "metadata": {
        "id": "xqxKKV1UFZCQ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fp_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KVfF646eFdu6",
        "outputId": "48fa9eeb-1e4a-490e-a12b-cc0a5a523b42"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0     1     2     3     4     5     6     7     8     9     ...  1014  \\\n",
              "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "1        0     0     0     0     0     1     0     0     0     0  ...     0   \n",
              "2        0     1     0     0     0     0     0     0     0     0  ...     0   \n",
              "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "7260     0     1     0     0     0     0     0     0     0     0  ...     1   \n",
              "7261     0     0     0     0     0     0     0     1     0     0  ...     0   \n",
              "7262     0     0     0     0     0     0     0     1     0     0  ...     0   \n",
              "7263     0     0     0     1     0     0     0     0     0     0  ...     0   \n",
              "7264     0     0     0     1     0     0     0     0     0     0  ...     0   \n",
              "\n",
              "      1015  1016  1017  1018  1019  1020  1021  1022  1023  \n",
              "0        0     0     0     0     0     0     0     0     0  \n",
              "1        0     0     0     0     1     0     0     0     0  \n",
              "2        0     0     0     0     0     0     0     0     0  \n",
              "3        0     0     0     0     0     0     0     0     0  \n",
              "4        0     0     0     0     0     0     0     0     0  \n",
              "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "7260     0     0     0     0     0     0     0     0     0  \n",
              "7261     0     0     1     0     1     0     0     0     0  \n",
              "7262     0     0     0     0     1     0     0     0     0  \n",
              "7263     0     0     0     0     1     0     0     0     0  \n",
              "7264     0     0     0     0     1     0     0     0     0  \n",
              "\n",
              "[7265 rows x 1024 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ec2e695-bed6-4ae4-a1de-e943395c7dd7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7260</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7261</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7262</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7264</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7265 rows × 1024 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ec2e695-bed6-4ae4-a1de-e943395c7dd7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ec2e695-bed6-4ae4-a1de-e943395c7dd7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ec2e695-bed6-4ae4-a1de-e943395c7dd7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 입력\n",
        "------\n",
        "파이토치에서는 데이터를 효율적으로 읽어오고 다루기 위한 함수들을 `torch.utils.data` 라는 모듈에 구현되어 있다. "
      ],
      "metadata": {
        "id": "6tAqRfFJPdnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data"
      ],
      "metadata": {
        "id": "UGgJmMytPZ4U"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서는 데이터를 효과적으로 다루기 위해서 `torch.utils.data.Dataset`과 `torch.utils.data.DataLoader`라는 두가지 클래스를 제공하고 있다. \n",
        "\n",
        "위의 두 클래스는 데이터를 읽어들이고 학습/테스트 셋을 나누고 편리하게 읽어들이기 위한 기능을 제공한다. "
      ],
      "metadata": {
        "id": "OYQZdc-_PyOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `data.Dataset`\n",
        "-----\n",
        "\n",
        "data.Dataset은 전체 데이터를 저장하고 필요한 데이터를 뽑아내는 class이다. \n",
        "\n",
        "이 class를 정의하기 위해서는 전체 데이터 길이를 리턴하는 `__len__` 함수와 `__getitem__` 함수를 정의해주어야 한다. \n",
        "\n",
        "위에서 사용한 분자를 feature vector로 바꾸는 procedure를 이용하여 Tox21Dataset 클래스를 아래와 같이 정의해보자. "
      ],
      "metadata": {
        "id": "gPNwSen9QvjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tox21Dataset(data.Dataset):\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            raw_df: 초기 tox21 데이터\n",
        "            df_sub: \"NR-AR\"과 \"smiles\" 열 만으로 구성된 DataFrame\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.raw_df=pd.read_csv('https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/tox21.csv.gz')\n",
        "        self.df_sub=self.raw_df[[\"NR-AR\", \"smiles\"]].copy() # NR-AR과 smiles 열만 추출\n",
        "        self.df_sub=self.df_sub.dropna(axis='index', subset='NR-AR') # NR-AR column에 NaN이 있는 raw를 제거.\n",
        "        \n",
        "        fp_list = []\n",
        "        for smi in tqdm(self.df_sub[\"smiles\"]):\n",
        "          m = Chem.MolFromSmiles(smi)\n",
        "          fp = AllChem.GetMorganFingerprintAsBitVect(m,2,nBits=1024)\n",
        "          fp_list.append(fp.ToList())\n",
        "\n",
        "        self.data=torch.tensor(fp_list, dtype=torch.float32)  #input data to tensor\n",
        "        print(\"self.data:\")\n",
        "        print(self.data)\n",
        "        print(\"self.data.shape:\")\n",
        "        print(self.data.shape)\n",
        "\n",
        "        self.label=torch.tensor(self.df_sub[\"NR-AR\"].values, dtype=torch.float32)  # target_label to tensor\n",
        "        print(\"self.label:\")\n",
        "        print(self.label)\n",
        "        print(self.label.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        # 전체 데이터의 개수를 return하는 함수\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # idx 번째 데이터와 레이블을 리턴하는 함수\n",
        "        data_point = self.data[idx]\n",
        "        data_label = self.label[idx]\n",
        "        return data_point, data_label"
      ],
      "metadata": {
        "id": "engJeb-LFeDx"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tox21 = Tox21Dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2D7KhpUQKEr",
        "outputId": "2ddde330-5e70-4590-b312-e6d385d7352e"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/7265 [00:00<?, ?it/s][02:36:54] WARNING: not removing hydrogen atom without neighbors\n",
            "100%|██████████| 7265/7265 [00:01<00:00, 5146.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.data:\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "self.data.shape:\n",
            "torch.Size([7265, 1024])\n",
            "self.label:\n",
            "tensor([0., 0., 0.,  ..., 1., 1., 0.])\n",
            "torch.Size([7265])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서는 `torch.utils.data.random_split` 함수를 이용해서 train/test 셋을 나눌 수 있다. "
      ],
      "metadata": {
        "id": "B32p5GEITR9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_size = len(tox21)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "validation_size = int(dataset_size * 0.1)\n",
        "test_size = dataset_size - train_size - validation_size\n",
        "\n",
        "train_dataset, validation_dataset, test_dataset = data.random_split(tox21, [train_size, validation_size, test_size])\n",
        "\n",
        "print(f\"Training Data Size : {len(train_dataset)}\")\n",
        "print(f\"Validation Data Size : {len(validation_dataset)}\")\n",
        "print(f\"Testing Data Size : {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPa_a6N_QMg0",
        "outputId": "96349be2-3654-408e-cb47-d4bf2b51bad1"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Size : 5812\n",
            "Validation Data Size : 726\n",
            "Testing Data Size : 727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zz8LsV2Vk71",
        "outputId": "3a754972-3273-4e77-9c05-2486cef8b2b3"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DataLoader 클래스\n",
        "\n",
        "`torch.utils.data.DataLoader` 클래스는 자동 일괄 처리, 다중 프로세스 데이터 로드 및 더 많은 기능을 python iterable입니다. \n",
        "\n",
        "데이터 로더는 `__getitem__` 함수를 사용하여 데이터세트와 통신하고 출력을 첫 번째 차원에 텐서로 쌓아 배치를 형성합니다.\n",
        "\n",
        "데이터세트 클래스와 달리 일반적으로 자체 데이터 로더 클래스를 정의할 필요는 없지만 데이터세트를 입력으로 사용하여 개체를 만들 수 있습니다. \n",
        "\n",
        "또한 다음 입력 인수를 사용하여 데이터 로더를 구성할 수 있습니다([전체 문서](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)):\n",
        "\n",
        "* `batch_size`: 배치당 사용할 샘플 수\n",
        "* `shuffle`: True이면 무작위 순서로 데이터가 반환됩니다. 이것은 확률론을 도입하기 위한 훈련 중에 중요합니다.\n",
        "* `num_workers`: 데이터 로드에 사용할 하위 프로세스의 수입니다. 데이터의 크기가 크다면 더 많은 작업자가 권장되지만 Windows 컴퓨터에서 문제가 발생할 수 있습니다. 작은 데이터 세트의 경우 일반적으로 0 작업자가 더 빠릅니다.\n",
        "* `pin_memory`: True인 경우 데이터 로더는 Tensor를 반환하기 전에 CUDA 고정 메모리에 복사합니다. 이렇게 하면 GPU의 대용량 데이터 포인트를 읽어들이는 시간을 절약할 수 있습니다. 일반적으로 학습데이터 세트에 사용하는 것이 좋습니다.\n",
        "* `drop_last`: True인 경우 지정된 배치 크기보다 작은 경우 마지막 배치를 삭제합니다. 이는 데이터 세트 크기가 배치 크기의 배수가 아닌 경우에 발생합니다. 일관된 배치 크기를 유지하기 위해 훈련 중에 잠재적으로 도움이 될 수 있습니다."
      ],
      "metadata": {
        "id": "YT0yFTgiUNPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 배치학습(batch)\n",
        "\n",
        "배치는 한 번에 학습하는 데이터의 개수를 의미합니다. \n",
        "\n",
        "일반적으로 전체 데이터세트는 매우 크고, 그 데이터를 모두 한 번에 학습할 수는 없습니다. \n",
        "\n",
        "그렇기 때문에 컴퓨터의 메모리등을 고려해서 한 번에 학습하는 양을 batch라고 부릅니다. \n",
        "batch의 사이즈가 작으면 일반적으로 학습이 오래 걸리게 됩니다. \n",
        "batch의 사이즈가 너무 크면 out-of-memory 문제가 생기거나 또는 학습이 잘 되지 않는 경우들이 발생하게 됩니다. \n",
        "\n",
        "그리고 여러 batch를 지나서 모든 데이터를 한 번 학습했을 때, 이를 1 epoch 이라고 부릅니다. "
      ],
      "metadata": {
        "id": "-1pZJlU6Mvbv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://onesixx.com/wp-content/uploads/2022/10/image-15.png\" width=800>"
      ],
      "metadata": {
        "id": "WS-xGKBEMXcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = data.DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "LxpSBMsvTmNM"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loader = data.DataLoader(validation_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "YI5uhVA5Gvuz"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = data.DataLoader(validation_dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "AK00DeN1GzH5"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# next(iter(...)) catches the first batch of the data loader\n",
        "# If shuffle is True, this will return a different batch every time we run this cell\n",
        "# For iterating over the whole dataset, we can simple use \"for batch in data_loader: ...\"\n",
        "data_inputs, data_labels = next(iter(train_loader))\n",
        "\n",
        "# The shape of the outputs are [batch_size, d_1,...,d_N] where d_1,...,d_N are the \n",
        "# dimensions of the data point returned from the dataset class\n",
        "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AysJvnMZVgmi",
        "outputId": "de6f278b-04ec-4e61-9f59-1c7e3dd6904e"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data inputs torch.Size([8, 1024]) \n",
            " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "Data labels torch.Size([8]) \n",
            " tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 최적화 (Optimization)\n",
        "\n",
        "모델과 데이터셋이 준비된 후에는 모델 최적화를 수행해야 합니다. \n",
        "일반적인 파이토치의 모델 최적화는 다음의 과정을 통해서 이루어집니다. \n",
        "\n",
        "1. 데이터로더에서 하나의 배치를 가져온다. \n",
        "2. 배치의 데이터를 이용해서 예측을 수행한다. \n",
        "3. 예측과 true 값을 비교하여 손실함수를 계산한다. \n",
        "4. 손실함수의 기울기를 계산하여 역전파 계산을 수행한다. \n",
        "5. 역전파 계산을 통해 파라미터를 업데이트 한다. \n",
        "\n",
        "\n",
        "After defining the model and the dataset, it is time to prepare the optimization of the model. During training, we will perform the following steps:\n",
        "\n",
        "1. Get a batch from the data loader\n",
        "2. Obtain the predictions from the model for the batch\n",
        "3. Calculate the loss based on the difference between predictions and labels\n",
        "4. Backpropagation: calculate the gradients for every parameter with respect to the loss\n",
        "5. Update the parameters of the model in the direction of the gradients\n",
        "\n",
        "We have seen how we can do step 1, 2 and 4 in PyTorch. Now, we will look at step 3 and 5."
      ],
      "metadata": {
        "id": "cG3pSmSDXF-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 손실 함수 (Loss modules)\n",
        "\n",
        "이번 예제에서는 이항 분류 문제이므로 binary cross-entropy 손실 함수를 사용한다. \n",
        "\n",
        "파이토치에는 두가지의  binary cross-entropy 손실 함수가 내장되어 있다: `nn.BCELoss`, `nn.BCEWithLogitsLoss`.\n",
        "\n",
        "이 중에서 `nn.BCEWithLogitsLoss`는 sigmoid 계산을 한 번에 수행하기 때문에 수치적으로 더 안정하다. 그러므로 가능한 `nn.BCEWithLogitsLoss`를 사용하는 것이 좋다. \n",
        "\n",
        "추가적인 모든 손실 함수들은 다음의 링크에서 찾아볼 수 있다. \n",
        "(see [here](https://pytorch.org/docs/stable/nn.html#loss-functions) for a full list)"
      ],
      "metadata": {
        "id": "XxjCDB04Xtsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can calculate the loss for a batch by simply performing a few tensor operations as those are automatically added to the computation graph. For instance, for binary classification, we can use Binary Cross Entropy (BCE) which is defined as follows:\n",
        "\n",
        "${L}_{BCE} = -\\sum_i \\left[ y_i \\log x_i + (1 - y_i) \\log (1 - x_i) \\right]$\n",
        "\n",
        "where $y$ are our labels, and $x$ our predictions, both in the range of $[0,1]$. However, PyTorch already provides a list of predefined loss functions which we can use (see [here](https://pytorch.org/docs/stable/nn.html#loss-functions) for a full list). For instance, for BCE, PyTorch has two modules: `nn.BCELoss()`, `nn.BCEWithLogitsLoss()`. While `nn.BCELoss` expects the inputs $x$ to be in the range $[0,1]$, i.e. the output of a sigmoid, `nn.BCEWithLogitsLoss` combines a sigmoid layer and the BCE loss in a single class. This version is numerically more stable than using a plain Sigmoid followed by a BCE loss because of the logarithms applied in the loss function. Hence, it is adviced to use loss functions applied on \"logits\" where possible (remember to not apply a sigmoid on the output of the model in this case!). For our model defined above, we therefore use the module `nn.BCEWithLogitsLoss`. "
      ],
      "metadata": {
        "id": "PuXsRjrdJ128"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_module = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "5fTKWRc3Vh79"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stochastic Gradient Descent\n",
        "\n",
        "모델의 파라미터를 업데이트 하기 위해서는 loss function의 기울기를 계산 한 후, 그 기울기를 어떻게 따라갈지 방법을 정해야 한다. \n",
        "이에 대해서 다음 시간에 조금 더 자세히 다루도록 하겠지만 기본적으로는 계산된 기울기에 상수를 곱한 후, 기울기의 반대 방향으로 파라미터들을 업데이트 해준다. \n",
        "\n",
        "<img src=\"https://editor.analyticsvidhya.com/uploads/631731_P7z2BKhd0R-9uyn9ThDasA.png\" width=500>"
      ],
      "metadata": {
        "id": "_2_WJmhxXzez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For updating the parameters, PyTorch provides the package `torch.optim` that has most popular optimizers implemented. We will discuss the specific optimizers and their differences later in the course, but will for now use the simplest of them: `torch.optim.SGD`. Stochastic Gradient Descent updates parameters by multiplying the gradients with a small constant, called learning rate, and subtracting those from the parameters (hence minimizing the loss). Therefore, we slowly move towards the direction of minimizing the loss. A good default value of the learning rate for a small network as ours is 0.1. "
      ],
      "metadata": {
        "id": "Pb8sCPL1KqdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input to the optimizer are the parameters of the model: model.parameters()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "UGdPZeRqXv8c"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서는 다양한 optimizer를 제공하고 있으며, 전체 리스트는 다음 [페이지](https://pytorch.org/docs/stable/optim.html)에서 확인할 수 있다. \n",
        "\n",
        "optimizer는 step()과 zero_grad() 메소드를 가지고 있다. \n",
        "\n",
        "step()은 기울기의 반대방향으로 parameter들을 업데이트 해준다. \n",
        "\n",
        "zero_grad()는 기울기 값을 0으로 초기화 해준다. 기본적으로 파이토치에서 backward()가 불러질 때, 기존에 존재하는 기울기 값이 있으면, 그 값에 덧셈을 수행한다. \n",
        "그러므로 배치 학습을 진행할 때, 새로운 데이터의 배치가 들어오면 기울기를 새롭게 초기화 해주어야한다. "
      ],
      "metadata": {
        "id": "4lmrZwpYLnU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimizer provides two useful functions: `optimizer.step()`, and `optimizer.zero_grad()`. \n",
        "\n",
        "The step function updates the parameters based on the gradients as explained above. The function `optimizer.zero_grad()` sets the gradients of all parameters to zero. While this function seems less relevant at first, it is a crucial pre-step before performing backpropagation. If we call the `backward` function on the loss while the parameter gradients are non-zero from the previous batch, the new gradients would actually be added to the previous ones instead of overwriting them. This is done because a parameter might occur multiple times in a computation graph, and we need to sum the gradients in this case instead of replacing them. Hence, remember to call `optimizer.zero_grad()` before calculating the gradients of a batch."
      ],
      "metadata": {
        "id": "Jxi9tzrBX6Nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training\n",
        "\n",
        "이제 실제 학습을 진행해 봅시다. \n",
        "\n",
        "일단 새로운 모델을 하나 선언합니다. \n",
        "\n",
        "이번 예제에서는 입력의 차원이 1024차원이고 출력은 [0,1] 사이의 값을 가지는 실수 값 1개가 됩니다. \n",
        "\n",
        "출력 값이 1에 가까우면 독성이 있고, 0에 가까울 수록 독성이 없을 가능성이 높다는 것을 의미합니다. \n",
        "\n",
        "Finally, we are ready to train our model. As a first step, we create a slightly larger dataset and specify a data loader with a larger batch size. "
      ],
      "metadata": {
        "id": "B4iEBqGvYARE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleClassifier(num_inputs=1024, num_hidden=512, num_outputs=1)"
      ],
      "metadata": {
        "id": "QOTr08SGYlim"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "현재 가장 많이 사용되는 [Adam optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)를 사용해봅시다. "
      ],
      "metadata": {
        "id": "V4-jJod9NmxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input to the optimizer are the parameters of the model: model.parameters()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "Mkl_-e7N_lO3"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 구조 출력"
      ],
      "metadata": {
        "id": "7s_dthGoNqOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH_yeW0LY6v5",
        "outputId": "f6f0219f-fc25-4245-a81a-a10c3e627346"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleClassifier(\n",
            "  (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (act_fn): Tanh()\n",
            "  (linear2): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "한 번에 128개의 데이터를 학습합니다. "
      ],
      "metadata": {
        "id": "HzdYzrfvNkgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "Q7B2C5mIX3bf"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loader = data.DataLoader(validation_dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "fxVMbBPfH1i_"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델을 GPU에 올립니다. "
      ],
      "metadata": {
        "id": "fRWWGFrFOFKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Push model to device. Has to be only done once\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrt0aWPbYGjI",
        "outputId": "c180be82-c5b7-4723-c59f-d898f04eebfd"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleClassifier(\n",
              "  (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (act_fn): Tanh()\n",
              "  (linear2): Linear(in_features=512, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파이토치에서는 모델이 학습을 할 때는 학습 모드, 평가(예측)를 할 때는 평가 모드를 정의하게 됩니다. \n",
        "\n",
        "학습 모드에서는 기본적으로 파라미터들의 기울기 계산을 위한 준비를 하기 때문에 계산 시간이 오래 걸립니다. \n",
        "\n",
        "만일 파라미터 업데이트가 필요 없다면 기울기 계산도 필요 없기 때문에 eval 모드로 정의해주어야 합니다. "
      ],
      "metadata": {
        "id": "tLUegsN8OKVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, we set our model to training mode. This is done by calling `model.train()`. There exist certain modules that need to perform a different forward step during training than during testing (e.g. BatchNorm and Dropout), and we can switch between them using `model.train()` and `model.eval()`."
      ],
      "metadata": {
        "id": "E1AJbE9wYLrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
        "    # Set model to train mode\n",
        "    model.train() \n",
        "    train_loss_list = []\n",
        "    validation_loss_list = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        train_loss = 0.0\n",
        "        for data_inputs, data_labels in train_loader:\n",
        "            \n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "            \n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "            \n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels.float())\n",
        "            train_loss += loss.item() # sum over batches\n",
        "\n",
        "            ## Step 4: Perform backpropagation\n",
        "            # Before calculating the gradients, we need to ensure that they are all zero. \n",
        "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
        "            optimizer.zero_grad() \n",
        "            # Perform backpropagation\n",
        "            loss.backward()\n",
        "            \n",
        "            ## Step 5: Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "        # save a training loss at a given epoch\n",
        "        train_loss_list.append(train_loss)\n",
        "        ### end of training \n",
        "\n",
        "        ### evaluation using the validation set\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        for data_inputs, data_labels in validation_loader:\n",
        "            \n",
        "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
        "            data_inputs = data_inputs.to(device)\n",
        "            data_labels = data_labels.to(device)\n",
        "            \n",
        "            ## Step 2: Run the model on the input data\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
        "            \n",
        "            ## Step 3: Calculate the loss\n",
        "            loss = loss_module(preds, data_labels.float())\n",
        "            val_loss += loss.item() # sum over batches\n",
        "\n",
        "        validation_loss_list.append(val_loss)\n",
        "        #Print information out\n",
        "        if epoch % 5 == 0:\n",
        "          print(f'Epoch: {epoch:03d}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
        "          \n",
        "        model.train()\n",
        "    return train_loss_list, validation_loss_list"
      ],
      "metadata": {
        "id": "nkWDBwllYIZn"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, validation_loss = train_model(model, optimizer, train_loader, loss_module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeJJfcm7YXDP",
        "outputId": "0406f070-2194-40f5-c992-4165b5005a03"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 2/100 [00:00<00:13,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Training Loss: 22.1270, Validation Loss: 1.9797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 7/100 [00:00<00:12,  7.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 005, Training Loss: 7.0385, Validation Loss: 0.9520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 12/100 [00:01<00:11,  7.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Training Loss: 5.7439, Validation Loss: 0.8861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 17/100 [00:02<00:11,  7.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 015, Training Loss: 4.7537, Validation Loss: 0.8521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 22/100 [00:02<00:10,  7.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 020, Training Loss: 3.9610, Validation Loss: 0.8802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 27/100 [00:03<00:09,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 025, Training Loss: 3.3787, Validation Loss: 0.9076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 32/100 [00:04<00:08,  7.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 030, Training Loss: 2.9031, Validation Loss: 0.9454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 37/100 [00:04<00:08,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 035, Training Loss: 2.5586, Validation Loss: 1.0188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 42/100 [00:05<00:07,  7.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 040, Training Loss: 2.2562, Validation Loss: 1.0156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 47/100 [00:06<00:06,  7.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 045, Training Loss: 1.9911, Validation Loss: 1.1092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 52/100 [00:06<00:06,  7.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 050, Training Loss: 1.7926, Validation Loss: 1.2199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 57/100 [00:07<00:05,  7.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 055, Training Loss: 1.5833, Validation Loss: 1.3649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 62/100 [00:08<00:04,  7.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 060, Training Loss: 1.4274, Validation Loss: 1.3389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 67/100 [00:09<00:05,  6.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 065, Training Loss: 1.2790, Validation Loss: 1.4008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 72/100 [00:09<00:04,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 070, Training Loss: 1.1655, Validation Loss: 1.5929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 77/100 [00:10<00:04,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 075, Training Loss: 1.0489, Validation Loss: 1.5999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 82/100 [00:11<00:02,  6.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 080, Training Loss: 0.9701, Validation Loss: 1.8440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 87/100 [00:12<00:01,  7.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 085, Training Loss: 0.8654, Validation Loss: 1.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 92/100 [00:12<00:01,  7.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 090, Training Loss: 0.7913, Validation Loss: 2.0074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 97/100 [00:13<00:00,  7.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 095, Training Loss: 0.7340, Validation Loss: 2.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:13<00:00,  7.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib \n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "G33ZsYiKRY9Z"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss의 변화를 plot 해보자. "
      ],
      "metadata": {
        "id": "D1jaP7KoUBao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, '.', color='b', label='train')\n",
        "plt.plot(validation_loss, '.', color='orange', label='validation')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "8BHxEITfRUzI",
        "outputId": "4e1578a8-9252-4d6d-b76d-511a9925849e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbe5eb919d0>"
            ]
          },
          "metadata": {},
          "execution_count": 328
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving a model\n",
        "\n",
        "After finish training a model, we save the model to disk so that we can load the same weights at a later time. For this, we extract the so-called `state_dict` from the model which contains all learnable parameters. For our simple model, the state dict contains the following entries:"
      ],
      "metadata": {
        "id": "kqjxB5ZUZ3hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = model.state_dict()\n",
        "print(state_dict)"
      ],
      "metadata": {
        "id": "VU2BTpkzYXNW",
        "outputId": "13a5fc1d-b934-4fb9-a1eb-e71a512b90f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('linear1.weight', tensor([[-0.0162,  0.0406,  0.0210,  ..., -0.0476,  0.0006, -0.0168],\n",
            "        [-0.0076,  0.0122, -0.0054,  ..., -0.0290, -0.0062,  0.0225],\n",
            "        [-0.0138, -0.0421,  0.0042,  ...,  0.0389, -0.0028, -0.0254],\n",
            "        ...,\n",
            "        [-0.0135,  0.0140,  0.0150,  ...,  0.0045, -0.0230,  0.0163],\n",
            "        [ 0.0097, -0.0218, -0.0489,  ..., -0.0207,  0.0351,  0.0256],\n",
            "        [-0.0008, -0.0262, -0.0064,  ...,  0.0004,  0.0471, -0.0160]],\n",
            "       device='cuda:0')), ('linear1.bias', tensor([ 0.0292,  0.0700, -0.0653,  0.0274,  0.0693,  0.0647,  0.0745,  0.0718,\n",
            "        -0.0612,  0.0965, -0.0499,  0.0940,  0.0352,  0.0482, -0.0682, -0.0796,\n",
            "         0.1124, -0.0640, -0.0643,  0.0695, -0.0975, -0.1115, -0.0565, -0.0602,\n",
            "        -0.0715,  0.0808,  0.0840,  0.0926,  0.0666, -0.0365, -0.0536, -0.0603,\n",
            "        -0.0777,  0.0340,  0.0717,  0.0424,  0.0997, -0.1097, -0.0701, -0.0218,\n",
            "         0.0451,  0.0733,  0.1100, -0.0536,  0.0667,  0.1331, -0.1037,  0.0829,\n",
            "         0.0864,  0.0783,  0.0395,  0.0635, -0.0957, -0.0559, -0.0630, -0.1325,\n",
            "        -0.0352,  0.1076,  0.0778,  0.1147,  0.0759, -0.0523,  0.0543, -0.0841,\n",
            "        -0.0398, -0.0428, -0.0529,  0.0557,  0.1155,  0.0555,  0.0352, -0.0951,\n",
            "        -0.0896, -0.0881, -0.0671,  0.0657,  0.0841, -0.0696,  0.0885, -0.0388,\n",
            "        -0.1002, -0.0764, -0.1187, -0.0850,  0.0417, -0.0487, -0.0623,  0.0464,\n",
            "        -0.0878, -0.0521, -0.0945, -0.0958, -0.0744, -0.0861,  0.0727,  0.0471,\n",
            "         0.0822, -0.0580, -0.0875, -0.0479, -0.0486, -0.0562, -0.0472,  0.1180,\n",
            "         0.0380, -0.0698,  0.0340, -0.0717, -0.0732,  0.0580,  0.1070, -0.0630,\n",
            "        -0.0508, -0.0419, -0.0251,  0.0759,  0.0340, -0.0483,  0.0438,  0.0888,\n",
            "        -0.0840, -0.0800,  0.0813,  0.0826, -0.0831, -0.0693, -0.0886,  0.1317,\n",
            "         0.1206, -0.0507,  0.0498,  0.0378, -0.0567, -0.0603, -0.0595,  0.1496,\n",
            "        -0.0817,  0.0710, -0.0632,  0.0725, -0.0222, -0.0676, -0.0616, -0.0490,\n",
            "        -0.0657, -0.0477,  0.0521, -0.0426,  0.0714, -0.0315,  0.0770, -0.0737,\n",
            "         0.1376,  0.0857, -0.1081,  0.0507, -0.0517,  0.0956, -0.0420,  0.0729,\n",
            "         0.0862, -0.0541, -0.0406, -0.0701, -0.0798, -0.0401,  0.1079,  0.0848,\n",
            "         0.1046,  0.0419, -0.0545,  0.0838, -0.0253,  0.0802, -0.0579, -0.0490,\n",
            "        -0.0600,  0.0925, -0.0483, -0.0986,  0.0385, -0.0751, -0.0654, -0.0310,\n",
            "        -0.0331,  0.0827,  0.0874,  0.0729, -0.0548, -0.0795, -0.0270,  0.0985,\n",
            "         0.0767, -0.1041, -0.0948, -0.0659,  0.0976,  0.0704, -0.0358, -0.0590,\n",
            "         0.0749,  0.0387, -0.1050, -0.1010,  0.0541,  0.0713,  0.0945,  0.0477,\n",
            "        -0.0473, -0.0937,  0.0695,  0.0714, -0.0820, -0.0857, -0.0743, -0.0612,\n",
            "         0.0422,  0.0834, -0.1018,  0.0829,  0.1431, -0.0719, -0.1352, -0.0803,\n",
            "        -0.0745,  0.0612, -0.0512,  0.1076,  0.0371, -0.0536,  0.0582, -0.0797,\n",
            "         0.0587,  0.0860,  0.0425,  0.0349,  0.1066, -0.1233, -0.0726, -0.0818,\n",
            "        -0.0522, -0.0504,  0.0564,  0.0747,  0.0462,  0.0811,  0.0709, -0.0804,\n",
            "        -0.0514, -0.0854, -0.0232, -0.0614,  0.0930,  0.0661, -0.0941,  0.0228,\n",
            "         0.1136, -0.0983, -0.0754, -0.0987,  0.0802, -0.0392, -0.1118,  0.0989,\n",
            "         0.0550,  0.0928, -0.0794, -0.1287,  0.0797, -0.0785, -0.0520, -0.0721,\n",
            "         0.0684,  0.0447,  0.0344,  0.0667,  0.0305, -0.0469,  0.0457, -0.0803,\n",
            "        -0.0974, -0.0960, -0.0874,  0.0944, -0.0882, -0.0678,  0.0729,  0.0496,\n",
            "        -0.0776, -0.0402, -0.0854, -0.0696, -0.0551,  0.0837, -0.0767,  0.0491,\n",
            "         0.0901,  0.0499, -0.0393,  0.0876,  0.0764,  0.1044,  0.0565,  0.0913,\n",
            "         0.0629,  0.0429, -0.0571,  0.0522, -0.0780,  0.0756, -0.1003, -0.0407,\n",
            "        -0.0846, -0.0520, -0.0743, -0.0365,  0.0894, -0.0305,  0.0769, -0.0575,\n",
            "         0.0848, -0.1155,  0.0940,  0.0235,  0.1416,  0.1338,  0.1289, -0.0977,\n",
            "         0.0790, -0.0814,  0.0574, -0.0486, -0.0678, -0.0458,  0.0350, -0.0293,\n",
            "         0.0652, -0.0438, -0.1169, -0.0625,  0.1003, -0.0895, -0.0782, -0.0322,\n",
            "         0.0406, -0.0879, -0.0641,  0.0423,  0.1116,  0.0837,  0.0413, -0.0848,\n",
            "        -0.0762,  0.0356,  0.0616, -0.0742, -0.0834, -0.0616,  0.1086, -0.0633,\n",
            "         0.0972,  0.0417,  0.0220, -0.0744, -0.0486, -0.0805, -0.0531, -0.0720,\n",
            "        -0.0348,  0.0960, -0.0287, -0.1385, -0.0848,  0.0789,  0.1478, -0.0410,\n",
            "         0.0740, -0.0550, -0.0790,  0.0797,  0.0706, -0.0433,  0.0689,  0.0339,\n",
            "        -0.0322, -0.0640, -0.0851,  0.1104,  0.0855, -0.0797, -0.0553,  0.0948,\n",
            "        -0.0291,  0.1249, -0.0953, -0.1137,  0.1036,  0.0619,  0.0582, -0.0849,\n",
            "         0.0625,  0.0589,  0.0663, -0.1051, -0.0442,  0.0613,  0.0830,  0.0422,\n",
            "        -0.0614,  0.0516, -0.0412,  0.1226,  0.0410, -0.0348,  0.0628, -0.0603,\n",
            "         0.1348, -0.1003,  0.1356,  0.0743, -0.0845, -0.0832,  0.0931,  0.0829,\n",
            "         0.0468, -0.0341, -0.0777,  0.0866,  0.0526,  0.0923,  0.0691,  0.1200,\n",
            "         0.0917, -0.0508, -0.0421, -0.0729, -0.0665,  0.1071, -0.0673, -0.0512,\n",
            "        -0.0815, -0.0828,  0.0423, -0.0530, -0.0832,  0.1247, -0.0832,  0.0208,\n",
            "        -0.0849,  0.0823,  0.0700, -0.0739,  0.1204, -0.1011, -0.0764, -0.0914,\n",
            "         0.0683, -0.0953,  0.0877,  0.0889, -0.0741,  0.0633,  0.0591, -0.0509,\n",
            "        -0.0685,  0.0549,  0.0866, -0.0934, -0.1165, -0.0736,  0.0866,  0.0729,\n",
            "        -0.0778,  0.0886, -0.0790,  0.0264, -0.0629,  0.1033, -0.0510,  0.0872,\n",
            "        -0.0613,  0.1241, -0.0653, -0.0461, -0.0643,  0.0897,  0.0611, -0.0642,\n",
            "         0.1065, -0.0456, -0.0985, -0.0963,  0.0774, -0.1544, -0.1417,  0.0702,\n",
            "        -0.0779, -0.0570,  0.0641,  0.0842,  0.0594,  0.0835,  0.1421, -0.0920,\n",
            "        -0.0555,  0.0855,  0.0774, -0.0955,  0.0571,  0.0695, -0.1086, -0.1295],\n",
            "       device='cuda:0')), ('linear2.weight', tensor([[-0.1657, -0.0844,  0.1493, -0.1111, -0.1437, -0.1437, -0.0941, -0.1772,\n",
            "          0.1675, -0.1679,  0.0682, -0.1264, -0.1608, -0.1660,  0.1661,  0.1159,\n",
            "         -0.1149,  0.1755,  0.1485, -0.1113,  0.1508,  0.1025,  0.1759,  0.1280,\n",
            "          0.1362, -0.1409, -0.1809, -0.1409, -0.1152,  0.1579,  0.1104,  0.0923,\n",
            "          0.1578, -0.0992, -0.1334, -0.0886, -0.1581,  0.1226,  0.1519,  0.1219,\n",
            "         -0.1564, -0.1314, -0.1499,  0.1098, -0.1661, -0.1869,  0.0976, -0.1528,\n",
            "         -0.1688, -0.1726, -0.1293, -0.1803,  0.0881,  0.1228,  0.1329,  0.1000,\n",
            "          0.1378, -0.0974, -0.1185, -0.0869, -0.1348,  0.1738, -0.0754,  0.1446,\n",
            "          0.1269,  0.1318,  0.1652, -0.1396, -0.0611, -0.1793, -0.1263,  0.1331,\n",
            "          0.0860,  0.2046,  0.1376, -0.1089, -0.1025,  0.1708, -0.1322,  0.1579,\n",
            "          0.1849,  0.1128,  0.1887,  0.0896, -0.1035,  0.1267,  0.1794, -0.1546,\n",
            "          0.1593,  0.1441,  0.1141,  0.1478,  0.1388,  0.1075, -0.1481, -0.1200,\n",
            "         -0.1377,  0.1375,  0.1504,  0.1180,  0.1796,  0.1659,  0.1314, -0.0909,\n",
            "         -0.1119,  0.1438, -0.1881,  0.1306,  0.1779, -0.1197, -0.1238,  0.1550,\n",
            "          0.1638,  0.1603,  0.1199, -0.1723, -0.1336,  0.1756, -0.1553, -0.1354,\n",
            "          0.0984,  0.1149, -0.1446, -0.1430,  0.1441,  0.1719,  0.1342, -0.1543,\n",
            "         -0.1833,  0.1383, -0.1625, -0.1044,  0.1618,  0.1232,  0.1266, -0.1612,\n",
            "          0.1065, -0.1248,  0.0936, -0.1697,  0.1414,  0.1752,  0.1313,  0.1163,\n",
            "          0.1455,  0.1341, -0.1672,  0.1428, -0.1224,  0.1457, -0.1040,  0.1053,\n",
            "         -0.1043, -0.1070,  0.1843, -0.1517,  0.1168, -0.1538,  0.1688, -0.1288,\n",
            "         -0.0960,  0.1388,  0.0970,  0.1337,  0.1055,  0.1269, -0.1772, -0.1937,\n",
            "         -0.1199, -0.1521,  0.1594, -0.0874,  0.1310, -0.1771,  0.1511,  0.1708,\n",
            "          0.1401, -0.1818,  0.1658,  0.1710, -0.0869,  0.0914,  0.1738,  0.1504,\n",
            "          0.1389, -0.1753, -0.1331, -0.1848,  0.1574,  0.1010,  0.1011, -0.1612,\n",
            "         -0.1216,  0.1366,  0.0991,  0.1628, -0.1481, -0.1500,  0.1451,  0.1746,\n",
            "         -0.1580, -0.1273,  0.1050,  0.1646, -0.0931, -0.1464, -0.1257, -0.1662,\n",
            "          0.1698,  0.1758, -0.1215, -0.1525,  0.1159,  0.1041,  0.1669,  0.1705,\n",
            "         -0.1263, -0.1608,  0.1749, -0.1580, -0.1161,  0.1452,  0.1603,  0.1712,\n",
            "          0.1178, -0.1625,  0.1495, -0.1744, -0.1571,  0.1451, -0.1335,  0.1506,\n",
            "         -0.1230, -0.1784, -0.1655, -0.0959, -0.1231,  0.1024,  0.1344,  0.1193,\n",
            "          0.1314,  0.1026, -0.1631, -0.1150, -0.1539, -0.1229, -0.1250,  0.0875,\n",
            "          0.0821,  0.1585,  0.1412,  0.1080, -0.1366, -0.1453,  0.0939, -0.1494,\n",
            "         -0.1378,  0.1890,  0.1644,  0.1447, -0.1451,  0.1189,  0.1315, -0.1168,\n",
            "         -0.1277, -0.1688,  0.1141,  0.0984, -0.1257,  0.1892,  0.1349,  0.1736,\n",
            "         -0.0923, -0.1754, -0.1385, -0.1640, -0.1221,  0.1226, -0.1555,  0.1843,\n",
            "          0.1569,  0.1423,  0.1476, -0.1327,  0.1243,  0.1396, -0.1808, -0.1489,\n",
            "          0.0939,  0.1606,  0.1277,  0.1011,  0.1692, -0.1138,  0.1107, -0.1627,\n",
            "         -0.0945, -0.1349,  0.1245, -0.1021, -0.1664, -0.1290, -0.1075, -0.1061,\n",
            "         -0.1656, -0.1069,  0.1865, -0.1633,  0.1132, -0.1437,  0.1613,  0.1048,\n",
            "          0.1784,  0.1183,  0.1245,  0.1099, -0.1242,  0.1448, -0.1464,  0.1527,\n",
            "         -0.1162,  0.1034, -0.1297, -0.1348, -0.1054, -0.1297, -0.1163,  0.1252,\n",
            "         -0.1815,  0.1625, -0.1284,  0.1008,  0.1860,  0.1664, -0.1150,  0.1305,\n",
            "         -0.1541,  0.1045,  0.1247,  0.1473, -0.1190,  0.1302,  0.1703,  0.1727,\n",
            "         -0.1156,  0.1117,  0.2014, -0.1151, -0.1072, -0.1708, -0.1478,  0.1432,\n",
            "          0.1095, -0.1291, -0.1663,  0.1617,  0.1097,  0.1563, -0.1555,  0.0842,\n",
            "         -0.1353, -0.1315, -0.0871,  0.1318,  0.1643,  0.1151,  0.1654,  0.1195,\n",
            "          0.1492, -0.1661,  0.1358,  0.1154,  0.1917, -0.1680, -0.1849,  0.1622,\n",
            "         -0.0763,  0.1730,  0.1782, -0.1148, -0.1110,  0.1272, -0.1826, -0.1385,\n",
            "          0.1231,  0.0969,  0.1560, -0.1736, -0.1547,  0.1033,  0.1796, -0.1213,\n",
            "          0.1165, -0.1159,  0.1098,  0.0972, -0.0832, -0.1338, -0.1478,  0.1419,\n",
            "         -0.1604, -0.1448, -0.1083,  0.1253,  0.1703, -0.1726, -0.1287, -0.1082,\n",
            "          0.0996, -0.1655,  0.1498, -0.0915, -0.1260,  0.1470, -0.1134,  0.1782,\n",
            "         -0.1487,  0.1691, -0.1647, -0.1543,  0.0913,  0.1892, -0.1417, -0.1280,\n",
            "         -0.1187,  0.1452,  0.1378, -0.1773, -0.1611, -0.1784, -0.0794, -0.1371,\n",
            "         -0.1253,  0.1621,  0.1506,  0.1741,  0.1255, -0.1493,  0.1265,  0.0995,\n",
            "          0.1202,  0.1444, -0.1277,  0.1467,  0.1509, -0.1478,  0.1393, -0.1143,\n",
            "          0.1554, -0.1746, -0.1738,  0.1324, -0.1642,  0.1795,  0.1187,  0.1345,\n",
            "         -0.1232,  0.1613, -0.1437, -0.1110,  0.0817, -0.1149, -0.1659,  0.1312,\n",
            "          0.1576, -0.1030, -0.1178,  0.1780,  0.1092,  0.1364, -0.1464, -0.1815,\n",
            "          0.1073, -0.1323,  0.1310, -0.1244,  0.1091, -0.1083,  0.0843, -0.0891,\n",
            "          0.1851, -0.0955,  0.1665,  0.1778,  0.1549, -0.1017, -0.1580,  0.1602,\n",
            "         -0.1286,  0.1596,  0.1407,  0.0825, -0.1492,  0.1567,  0.1157, -0.1260,\n",
            "          0.1330,  0.1133, -0.1323, -0.0995, -0.1667, -0.1299, -0.1683,  0.1855,\n",
            "          0.1255, -0.1240, -0.1390,  0.1408, -0.1377, -0.1499,  0.1010,  0.1636]],\n",
            "       device='cuda:0')), ('linear2.bias', tensor([0.0008], device='cuda:0'))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To save the state dictionary, we can use `torch.save`:\n"
      ],
      "metadata": {
        "id": "0-UUwNxxaH6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(object, filename). For the filename, any extension can be used\n",
        "torch.save(state_dict, \"our_model.tar\")"
      ],
      "metadata": {
        "id": "qSyN6iRZZzi7"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load a model from a state dict, we use the function `torch.load` to load the state dict from the disk, and the module function `load_state_dict` to overwrite our parameters with the new values:"
      ],
      "metadata": {
        "id": "DDpmnEmaaK5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load state dict from the disk (make sure it is the same name as above)\n",
        "state_dict = torch.load(\"our_model.tar\")\n",
        "\n",
        "# Create a new model and load the state\n",
        "new_model = SimpleClassifier(num_inputs=1024, num_hidden=512, num_outputs=1)\n",
        "new_model.load_state_dict(state_dict)\n",
        "\n",
        "# Verify that the parameters are the same\n",
        "print(\"Original model\\n\", model.state_dict())\n",
        "print(\"\\nLoaded model\\n\", new_model.state_dict())"
      ],
      "metadata": {
        "id": "FO71EECfaKk9",
        "outputId": "67804808-4cdd-4cbc-efb5-5323acfb41ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model\n",
            " OrderedDict([('linear1.weight', tensor([[-0.0162,  0.0406,  0.0210,  ..., -0.0476,  0.0006, -0.0168],\n",
            "        [-0.0076,  0.0122, -0.0054,  ..., -0.0290, -0.0062,  0.0225],\n",
            "        [-0.0138, -0.0421,  0.0042,  ...,  0.0389, -0.0028, -0.0254],\n",
            "        ...,\n",
            "        [-0.0135,  0.0140,  0.0150,  ...,  0.0045, -0.0230,  0.0163],\n",
            "        [ 0.0097, -0.0218, -0.0489,  ..., -0.0207,  0.0351,  0.0256],\n",
            "        [-0.0008, -0.0262, -0.0064,  ...,  0.0004,  0.0471, -0.0160]],\n",
            "       device='cuda:0')), ('linear1.bias', tensor([ 0.0292,  0.0700, -0.0653,  0.0274,  0.0693,  0.0647,  0.0745,  0.0718,\n",
            "        -0.0612,  0.0965, -0.0499,  0.0940,  0.0352,  0.0482, -0.0682, -0.0796,\n",
            "         0.1124, -0.0640, -0.0643,  0.0695, -0.0975, -0.1115, -0.0565, -0.0602,\n",
            "        -0.0715,  0.0808,  0.0840,  0.0926,  0.0666, -0.0365, -0.0536, -0.0603,\n",
            "        -0.0777,  0.0340,  0.0717,  0.0424,  0.0997, -0.1097, -0.0701, -0.0218,\n",
            "         0.0451,  0.0733,  0.1100, -0.0536,  0.0667,  0.1331, -0.1037,  0.0829,\n",
            "         0.0864,  0.0783,  0.0395,  0.0635, -0.0957, -0.0559, -0.0630, -0.1325,\n",
            "        -0.0352,  0.1076,  0.0778,  0.1147,  0.0759, -0.0523,  0.0543, -0.0841,\n",
            "        -0.0398, -0.0428, -0.0529,  0.0557,  0.1155,  0.0555,  0.0352, -0.0951,\n",
            "        -0.0896, -0.0881, -0.0671,  0.0657,  0.0841, -0.0696,  0.0885, -0.0388,\n",
            "        -0.1002, -0.0764, -0.1187, -0.0850,  0.0417, -0.0487, -0.0623,  0.0464,\n",
            "        -0.0878, -0.0521, -0.0945, -0.0958, -0.0744, -0.0861,  0.0727,  0.0471,\n",
            "         0.0822, -0.0580, -0.0875, -0.0479, -0.0486, -0.0562, -0.0472,  0.1180,\n",
            "         0.0380, -0.0698,  0.0340, -0.0717, -0.0732,  0.0580,  0.1070, -0.0630,\n",
            "        -0.0508, -0.0419, -0.0251,  0.0759,  0.0340, -0.0483,  0.0438,  0.0888,\n",
            "        -0.0840, -0.0800,  0.0813,  0.0826, -0.0831, -0.0693, -0.0886,  0.1317,\n",
            "         0.1206, -0.0507,  0.0498,  0.0378, -0.0567, -0.0603, -0.0595,  0.1496,\n",
            "        -0.0817,  0.0710, -0.0632,  0.0725, -0.0222, -0.0676, -0.0616, -0.0490,\n",
            "        -0.0657, -0.0477,  0.0521, -0.0426,  0.0714, -0.0315,  0.0770, -0.0737,\n",
            "         0.1376,  0.0857, -0.1081,  0.0507, -0.0517,  0.0956, -0.0420,  0.0729,\n",
            "         0.0862, -0.0541, -0.0406, -0.0701, -0.0798, -0.0401,  0.1079,  0.0848,\n",
            "         0.1046,  0.0419, -0.0545,  0.0838, -0.0253,  0.0802, -0.0579, -0.0490,\n",
            "        -0.0600,  0.0925, -0.0483, -0.0986,  0.0385, -0.0751, -0.0654, -0.0310,\n",
            "        -0.0331,  0.0827,  0.0874,  0.0729, -0.0548, -0.0795, -0.0270,  0.0985,\n",
            "         0.0767, -0.1041, -0.0948, -0.0659,  0.0976,  0.0704, -0.0358, -0.0590,\n",
            "         0.0749,  0.0387, -0.1050, -0.1010,  0.0541,  0.0713,  0.0945,  0.0477,\n",
            "        -0.0473, -0.0937,  0.0695,  0.0714, -0.0820, -0.0857, -0.0743, -0.0612,\n",
            "         0.0422,  0.0834, -0.1018,  0.0829,  0.1431, -0.0719, -0.1352, -0.0803,\n",
            "        -0.0745,  0.0612, -0.0512,  0.1076,  0.0371, -0.0536,  0.0582, -0.0797,\n",
            "         0.0587,  0.0860,  0.0425,  0.0349,  0.1066, -0.1233, -0.0726, -0.0818,\n",
            "        -0.0522, -0.0504,  0.0564,  0.0747,  0.0462,  0.0811,  0.0709, -0.0804,\n",
            "        -0.0514, -0.0854, -0.0232, -0.0614,  0.0930,  0.0661, -0.0941,  0.0228,\n",
            "         0.1136, -0.0983, -0.0754, -0.0987,  0.0802, -0.0392, -0.1118,  0.0989,\n",
            "         0.0550,  0.0928, -0.0794, -0.1287,  0.0797, -0.0785, -0.0520, -0.0721,\n",
            "         0.0684,  0.0447,  0.0344,  0.0667,  0.0305, -0.0469,  0.0457, -0.0803,\n",
            "        -0.0974, -0.0960, -0.0874,  0.0944, -0.0882, -0.0678,  0.0729,  0.0496,\n",
            "        -0.0776, -0.0402, -0.0854, -0.0696, -0.0551,  0.0837, -0.0767,  0.0491,\n",
            "         0.0901,  0.0499, -0.0393,  0.0876,  0.0764,  0.1044,  0.0565,  0.0913,\n",
            "         0.0629,  0.0429, -0.0571,  0.0522, -0.0780,  0.0756, -0.1003, -0.0407,\n",
            "        -0.0846, -0.0520, -0.0743, -0.0365,  0.0894, -0.0305,  0.0769, -0.0575,\n",
            "         0.0848, -0.1155,  0.0940,  0.0235,  0.1416,  0.1338,  0.1289, -0.0977,\n",
            "         0.0790, -0.0814,  0.0574, -0.0486, -0.0678, -0.0458,  0.0350, -0.0293,\n",
            "         0.0652, -0.0438, -0.1169, -0.0625,  0.1003, -0.0895, -0.0782, -0.0322,\n",
            "         0.0406, -0.0879, -0.0641,  0.0423,  0.1116,  0.0837,  0.0413, -0.0848,\n",
            "        -0.0762,  0.0356,  0.0616, -0.0742, -0.0834, -0.0616,  0.1086, -0.0633,\n",
            "         0.0972,  0.0417,  0.0220, -0.0744, -0.0486, -0.0805, -0.0531, -0.0720,\n",
            "        -0.0348,  0.0960, -0.0287, -0.1385, -0.0848,  0.0789,  0.1478, -0.0410,\n",
            "         0.0740, -0.0550, -0.0790,  0.0797,  0.0706, -0.0433,  0.0689,  0.0339,\n",
            "        -0.0322, -0.0640, -0.0851,  0.1104,  0.0855, -0.0797, -0.0553,  0.0948,\n",
            "        -0.0291,  0.1249, -0.0953, -0.1137,  0.1036,  0.0619,  0.0582, -0.0849,\n",
            "         0.0625,  0.0589,  0.0663, -0.1051, -0.0442,  0.0613,  0.0830,  0.0422,\n",
            "        -0.0614,  0.0516, -0.0412,  0.1226,  0.0410, -0.0348,  0.0628, -0.0603,\n",
            "         0.1348, -0.1003,  0.1356,  0.0743, -0.0845, -0.0832,  0.0931,  0.0829,\n",
            "         0.0468, -0.0341, -0.0777,  0.0866,  0.0526,  0.0923,  0.0691,  0.1200,\n",
            "         0.0917, -0.0508, -0.0421, -0.0729, -0.0665,  0.1071, -0.0673, -0.0512,\n",
            "        -0.0815, -0.0828,  0.0423, -0.0530, -0.0832,  0.1247, -0.0832,  0.0208,\n",
            "        -0.0849,  0.0823,  0.0700, -0.0739,  0.1204, -0.1011, -0.0764, -0.0914,\n",
            "         0.0683, -0.0953,  0.0877,  0.0889, -0.0741,  0.0633,  0.0591, -0.0509,\n",
            "        -0.0685,  0.0549,  0.0866, -0.0934, -0.1165, -0.0736,  0.0866,  0.0729,\n",
            "        -0.0778,  0.0886, -0.0790,  0.0264, -0.0629,  0.1033, -0.0510,  0.0872,\n",
            "        -0.0613,  0.1241, -0.0653, -0.0461, -0.0643,  0.0897,  0.0611, -0.0642,\n",
            "         0.1065, -0.0456, -0.0985, -0.0963,  0.0774, -0.1544, -0.1417,  0.0702,\n",
            "        -0.0779, -0.0570,  0.0641,  0.0842,  0.0594,  0.0835,  0.1421, -0.0920,\n",
            "        -0.0555,  0.0855,  0.0774, -0.0955,  0.0571,  0.0695, -0.1086, -0.1295],\n",
            "       device='cuda:0')), ('linear2.weight', tensor([[-0.1657, -0.0844,  0.1493, -0.1111, -0.1437, -0.1437, -0.0941, -0.1772,\n",
            "          0.1675, -0.1679,  0.0682, -0.1264, -0.1608, -0.1660,  0.1661,  0.1159,\n",
            "         -0.1149,  0.1755,  0.1485, -0.1113,  0.1508,  0.1025,  0.1759,  0.1280,\n",
            "          0.1362, -0.1409, -0.1809, -0.1409, -0.1152,  0.1579,  0.1104,  0.0923,\n",
            "          0.1578, -0.0992, -0.1334, -0.0886, -0.1581,  0.1226,  0.1519,  0.1219,\n",
            "         -0.1564, -0.1314, -0.1499,  0.1098, -0.1661, -0.1869,  0.0976, -0.1528,\n",
            "         -0.1688, -0.1726, -0.1293, -0.1803,  0.0881,  0.1228,  0.1329,  0.1000,\n",
            "          0.1378, -0.0974, -0.1185, -0.0869, -0.1348,  0.1738, -0.0754,  0.1446,\n",
            "          0.1269,  0.1318,  0.1652, -0.1396, -0.0611, -0.1793, -0.1263,  0.1331,\n",
            "          0.0860,  0.2046,  0.1376, -0.1089, -0.1025,  0.1708, -0.1322,  0.1579,\n",
            "          0.1849,  0.1128,  0.1887,  0.0896, -0.1035,  0.1267,  0.1794, -0.1546,\n",
            "          0.1593,  0.1441,  0.1141,  0.1478,  0.1388,  0.1075, -0.1481, -0.1200,\n",
            "         -0.1377,  0.1375,  0.1504,  0.1180,  0.1796,  0.1659,  0.1314, -0.0909,\n",
            "         -0.1119,  0.1438, -0.1881,  0.1306,  0.1779, -0.1197, -0.1238,  0.1550,\n",
            "          0.1638,  0.1603,  0.1199, -0.1723, -0.1336,  0.1756, -0.1553, -0.1354,\n",
            "          0.0984,  0.1149, -0.1446, -0.1430,  0.1441,  0.1719,  0.1342, -0.1543,\n",
            "         -0.1833,  0.1383, -0.1625, -0.1044,  0.1618,  0.1232,  0.1266, -0.1612,\n",
            "          0.1065, -0.1248,  0.0936, -0.1697,  0.1414,  0.1752,  0.1313,  0.1163,\n",
            "          0.1455,  0.1341, -0.1672,  0.1428, -0.1224,  0.1457, -0.1040,  0.1053,\n",
            "         -0.1043, -0.1070,  0.1843, -0.1517,  0.1168, -0.1538,  0.1688, -0.1288,\n",
            "         -0.0960,  0.1388,  0.0970,  0.1337,  0.1055,  0.1269, -0.1772, -0.1937,\n",
            "         -0.1199, -0.1521,  0.1594, -0.0874,  0.1310, -0.1771,  0.1511,  0.1708,\n",
            "          0.1401, -0.1818,  0.1658,  0.1710, -0.0869,  0.0914,  0.1738,  0.1504,\n",
            "          0.1389, -0.1753, -0.1331, -0.1848,  0.1574,  0.1010,  0.1011, -0.1612,\n",
            "         -0.1216,  0.1366,  0.0991,  0.1628, -0.1481, -0.1500,  0.1451,  0.1746,\n",
            "         -0.1580, -0.1273,  0.1050,  0.1646, -0.0931, -0.1464, -0.1257, -0.1662,\n",
            "          0.1698,  0.1758, -0.1215, -0.1525,  0.1159,  0.1041,  0.1669,  0.1705,\n",
            "         -0.1263, -0.1608,  0.1749, -0.1580, -0.1161,  0.1452,  0.1603,  0.1712,\n",
            "          0.1178, -0.1625,  0.1495, -0.1744, -0.1571,  0.1451, -0.1335,  0.1506,\n",
            "         -0.1230, -0.1784, -0.1655, -0.0959, -0.1231,  0.1024,  0.1344,  0.1193,\n",
            "          0.1314,  0.1026, -0.1631, -0.1150, -0.1539, -0.1229, -0.1250,  0.0875,\n",
            "          0.0821,  0.1585,  0.1412,  0.1080, -0.1366, -0.1453,  0.0939, -0.1494,\n",
            "         -0.1378,  0.1890,  0.1644,  0.1447, -0.1451,  0.1189,  0.1315, -0.1168,\n",
            "         -0.1277, -0.1688,  0.1141,  0.0984, -0.1257,  0.1892,  0.1349,  0.1736,\n",
            "         -0.0923, -0.1754, -0.1385, -0.1640, -0.1221,  0.1226, -0.1555,  0.1843,\n",
            "          0.1569,  0.1423,  0.1476, -0.1327,  0.1243,  0.1396, -0.1808, -0.1489,\n",
            "          0.0939,  0.1606,  0.1277,  0.1011,  0.1692, -0.1138,  0.1107, -0.1627,\n",
            "         -0.0945, -0.1349,  0.1245, -0.1021, -0.1664, -0.1290, -0.1075, -0.1061,\n",
            "         -0.1656, -0.1069,  0.1865, -0.1633,  0.1132, -0.1437,  0.1613,  0.1048,\n",
            "          0.1784,  0.1183,  0.1245,  0.1099, -0.1242,  0.1448, -0.1464,  0.1527,\n",
            "         -0.1162,  0.1034, -0.1297, -0.1348, -0.1054, -0.1297, -0.1163,  0.1252,\n",
            "         -0.1815,  0.1625, -0.1284,  0.1008,  0.1860,  0.1664, -0.1150,  0.1305,\n",
            "         -0.1541,  0.1045,  0.1247,  0.1473, -0.1190,  0.1302,  0.1703,  0.1727,\n",
            "         -0.1156,  0.1117,  0.2014, -0.1151, -0.1072, -0.1708, -0.1478,  0.1432,\n",
            "          0.1095, -0.1291, -0.1663,  0.1617,  0.1097,  0.1563, -0.1555,  0.0842,\n",
            "         -0.1353, -0.1315, -0.0871,  0.1318,  0.1643,  0.1151,  0.1654,  0.1195,\n",
            "          0.1492, -0.1661,  0.1358,  0.1154,  0.1917, -0.1680, -0.1849,  0.1622,\n",
            "         -0.0763,  0.1730,  0.1782, -0.1148, -0.1110,  0.1272, -0.1826, -0.1385,\n",
            "          0.1231,  0.0969,  0.1560, -0.1736, -0.1547,  0.1033,  0.1796, -0.1213,\n",
            "          0.1165, -0.1159,  0.1098,  0.0972, -0.0832, -0.1338, -0.1478,  0.1419,\n",
            "         -0.1604, -0.1448, -0.1083,  0.1253,  0.1703, -0.1726, -0.1287, -0.1082,\n",
            "          0.0996, -0.1655,  0.1498, -0.0915, -0.1260,  0.1470, -0.1134,  0.1782,\n",
            "         -0.1487,  0.1691, -0.1647, -0.1543,  0.0913,  0.1892, -0.1417, -0.1280,\n",
            "         -0.1187,  0.1452,  0.1378, -0.1773, -0.1611, -0.1784, -0.0794, -0.1371,\n",
            "         -0.1253,  0.1621,  0.1506,  0.1741,  0.1255, -0.1493,  0.1265,  0.0995,\n",
            "          0.1202,  0.1444, -0.1277,  0.1467,  0.1509, -0.1478,  0.1393, -0.1143,\n",
            "          0.1554, -0.1746, -0.1738,  0.1324, -0.1642,  0.1795,  0.1187,  0.1345,\n",
            "         -0.1232,  0.1613, -0.1437, -0.1110,  0.0817, -0.1149, -0.1659,  0.1312,\n",
            "          0.1576, -0.1030, -0.1178,  0.1780,  0.1092,  0.1364, -0.1464, -0.1815,\n",
            "          0.1073, -0.1323,  0.1310, -0.1244,  0.1091, -0.1083,  0.0843, -0.0891,\n",
            "          0.1851, -0.0955,  0.1665,  0.1778,  0.1549, -0.1017, -0.1580,  0.1602,\n",
            "         -0.1286,  0.1596,  0.1407,  0.0825, -0.1492,  0.1567,  0.1157, -0.1260,\n",
            "          0.1330,  0.1133, -0.1323, -0.0995, -0.1667, -0.1299, -0.1683,  0.1855,\n",
            "          0.1255, -0.1240, -0.1390,  0.1408, -0.1377, -0.1499,  0.1010,  0.1636]],\n",
            "       device='cuda:0')), ('linear2.bias', tensor([0.0008], device='cuda:0'))])\n",
            "\n",
            "Loaded model\n",
            " OrderedDict([('linear1.weight', tensor([[-0.0162,  0.0406,  0.0210,  ..., -0.0476,  0.0006, -0.0168],\n",
            "        [-0.0076,  0.0122, -0.0054,  ..., -0.0290, -0.0062,  0.0225],\n",
            "        [-0.0138, -0.0421,  0.0042,  ...,  0.0389, -0.0028, -0.0254],\n",
            "        ...,\n",
            "        [-0.0135,  0.0140,  0.0150,  ...,  0.0045, -0.0230,  0.0163],\n",
            "        [ 0.0097, -0.0218, -0.0489,  ..., -0.0207,  0.0351,  0.0256],\n",
            "        [-0.0008, -0.0262, -0.0064,  ...,  0.0004,  0.0471, -0.0160]])), ('linear1.bias', tensor([ 0.0292,  0.0700, -0.0653,  0.0274,  0.0693,  0.0647,  0.0745,  0.0718,\n",
            "        -0.0612,  0.0965, -0.0499,  0.0940,  0.0352,  0.0482, -0.0682, -0.0796,\n",
            "         0.1124, -0.0640, -0.0643,  0.0695, -0.0975, -0.1115, -0.0565, -0.0602,\n",
            "        -0.0715,  0.0808,  0.0840,  0.0926,  0.0666, -0.0365, -0.0536, -0.0603,\n",
            "        -0.0777,  0.0340,  0.0717,  0.0424,  0.0997, -0.1097, -0.0701, -0.0218,\n",
            "         0.0451,  0.0733,  0.1100, -0.0536,  0.0667,  0.1331, -0.1037,  0.0829,\n",
            "         0.0864,  0.0783,  0.0395,  0.0635, -0.0957, -0.0559, -0.0630, -0.1325,\n",
            "        -0.0352,  0.1076,  0.0778,  0.1147,  0.0759, -0.0523,  0.0543, -0.0841,\n",
            "        -0.0398, -0.0428, -0.0529,  0.0557,  0.1155,  0.0555,  0.0352, -0.0951,\n",
            "        -0.0896, -0.0881, -0.0671,  0.0657,  0.0841, -0.0696,  0.0885, -0.0388,\n",
            "        -0.1002, -0.0764, -0.1187, -0.0850,  0.0417, -0.0487, -0.0623,  0.0464,\n",
            "        -0.0878, -0.0521, -0.0945, -0.0958, -0.0744, -0.0861,  0.0727,  0.0471,\n",
            "         0.0822, -0.0580, -0.0875, -0.0479, -0.0486, -0.0562, -0.0472,  0.1180,\n",
            "         0.0380, -0.0698,  0.0340, -0.0717, -0.0732,  0.0580,  0.1070, -0.0630,\n",
            "        -0.0508, -0.0419, -0.0251,  0.0759,  0.0340, -0.0483,  0.0438,  0.0888,\n",
            "        -0.0840, -0.0800,  0.0813,  0.0826, -0.0831, -0.0693, -0.0886,  0.1317,\n",
            "         0.1206, -0.0507,  0.0498,  0.0378, -0.0567, -0.0603, -0.0595,  0.1496,\n",
            "        -0.0817,  0.0710, -0.0632,  0.0725, -0.0222, -0.0676, -0.0616, -0.0490,\n",
            "        -0.0657, -0.0477,  0.0521, -0.0426,  0.0714, -0.0315,  0.0770, -0.0737,\n",
            "         0.1376,  0.0857, -0.1081,  0.0507, -0.0517,  0.0956, -0.0420,  0.0729,\n",
            "         0.0862, -0.0541, -0.0406, -0.0701, -0.0798, -0.0401,  0.1079,  0.0848,\n",
            "         0.1046,  0.0419, -0.0545,  0.0838, -0.0253,  0.0802, -0.0579, -0.0490,\n",
            "        -0.0600,  0.0925, -0.0483, -0.0986,  0.0385, -0.0751, -0.0654, -0.0310,\n",
            "        -0.0331,  0.0827,  0.0874,  0.0729, -0.0548, -0.0795, -0.0270,  0.0985,\n",
            "         0.0767, -0.1041, -0.0948, -0.0659,  0.0976,  0.0704, -0.0358, -0.0590,\n",
            "         0.0749,  0.0387, -0.1050, -0.1010,  0.0541,  0.0713,  0.0945,  0.0477,\n",
            "        -0.0473, -0.0937,  0.0695,  0.0714, -0.0820, -0.0857, -0.0743, -0.0612,\n",
            "         0.0422,  0.0834, -0.1018,  0.0829,  0.1431, -0.0719, -0.1352, -0.0803,\n",
            "        -0.0745,  0.0612, -0.0512,  0.1076,  0.0371, -0.0536,  0.0582, -0.0797,\n",
            "         0.0587,  0.0860,  0.0425,  0.0349,  0.1066, -0.1233, -0.0726, -0.0818,\n",
            "        -0.0522, -0.0504,  0.0564,  0.0747,  0.0462,  0.0811,  0.0709, -0.0804,\n",
            "        -0.0514, -0.0854, -0.0232, -0.0614,  0.0930,  0.0661, -0.0941,  0.0228,\n",
            "         0.1136, -0.0983, -0.0754, -0.0987,  0.0802, -0.0392, -0.1118,  0.0989,\n",
            "         0.0550,  0.0928, -0.0794, -0.1287,  0.0797, -0.0785, -0.0520, -0.0721,\n",
            "         0.0684,  0.0447,  0.0344,  0.0667,  0.0305, -0.0469,  0.0457, -0.0803,\n",
            "        -0.0974, -0.0960, -0.0874,  0.0944, -0.0882, -0.0678,  0.0729,  0.0496,\n",
            "        -0.0776, -0.0402, -0.0854, -0.0696, -0.0551,  0.0837, -0.0767,  0.0491,\n",
            "         0.0901,  0.0499, -0.0393,  0.0876,  0.0764,  0.1044,  0.0565,  0.0913,\n",
            "         0.0629,  0.0429, -0.0571,  0.0522, -0.0780,  0.0756, -0.1003, -0.0407,\n",
            "        -0.0846, -0.0520, -0.0743, -0.0365,  0.0894, -0.0305,  0.0769, -0.0575,\n",
            "         0.0848, -0.1155,  0.0940,  0.0235,  0.1416,  0.1338,  0.1289, -0.0977,\n",
            "         0.0790, -0.0814,  0.0574, -0.0486, -0.0678, -0.0458,  0.0350, -0.0293,\n",
            "         0.0652, -0.0438, -0.1169, -0.0625,  0.1003, -0.0895, -0.0782, -0.0322,\n",
            "         0.0406, -0.0879, -0.0641,  0.0423,  0.1116,  0.0837,  0.0413, -0.0848,\n",
            "        -0.0762,  0.0356,  0.0616, -0.0742, -0.0834, -0.0616,  0.1086, -0.0633,\n",
            "         0.0972,  0.0417,  0.0220, -0.0744, -0.0486, -0.0805, -0.0531, -0.0720,\n",
            "        -0.0348,  0.0960, -0.0287, -0.1385, -0.0848,  0.0789,  0.1478, -0.0410,\n",
            "         0.0740, -0.0550, -0.0790,  0.0797,  0.0706, -0.0433,  0.0689,  0.0339,\n",
            "        -0.0322, -0.0640, -0.0851,  0.1104,  0.0855, -0.0797, -0.0553,  0.0948,\n",
            "        -0.0291,  0.1249, -0.0953, -0.1137,  0.1036,  0.0619,  0.0582, -0.0849,\n",
            "         0.0625,  0.0589,  0.0663, -0.1051, -0.0442,  0.0613,  0.0830,  0.0422,\n",
            "        -0.0614,  0.0516, -0.0412,  0.1226,  0.0410, -0.0348,  0.0628, -0.0603,\n",
            "         0.1348, -0.1003,  0.1356,  0.0743, -0.0845, -0.0832,  0.0931,  0.0829,\n",
            "         0.0468, -0.0341, -0.0777,  0.0866,  0.0526,  0.0923,  0.0691,  0.1200,\n",
            "         0.0917, -0.0508, -0.0421, -0.0729, -0.0665,  0.1071, -0.0673, -0.0512,\n",
            "        -0.0815, -0.0828,  0.0423, -0.0530, -0.0832,  0.1247, -0.0832,  0.0208,\n",
            "        -0.0849,  0.0823,  0.0700, -0.0739,  0.1204, -0.1011, -0.0764, -0.0914,\n",
            "         0.0683, -0.0953,  0.0877,  0.0889, -0.0741,  0.0633,  0.0591, -0.0509,\n",
            "        -0.0685,  0.0549,  0.0866, -0.0934, -0.1165, -0.0736,  0.0866,  0.0729,\n",
            "        -0.0778,  0.0886, -0.0790,  0.0264, -0.0629,  0.1033, -0.0510,  0.0872,\n",
            "        -0.0613,  0.1241, -0.0653, -0.0461, -0.0643,  0.0897,  0.0611, -0.0642,\n",
            "         0.1065, -0.0456, -0.0985, -0.0963,  0.0774, -0.1544, -0.1417,  0.0702,\n",
            "        -0.0779, -0.0570,  0.0641,  0.0842,  0.0594,  0.0835,  0.1421, -0.0920,\n",
            "        -0.0555,  0.0855,  0.0774, -0.0955,  0.0571,  0.0695, -0.1086, -0.1295])), ('linear2.weight', tensor([[-0.1657, -0.0844,  0.1493, -0.1111, -0.1437, -0.1437, -0.0941, -0.1772,\n",
            "          0.1675, -0.1679,  0.0682, -0.1264, -0.1608, -0.1660,  0.1661,  0.1159,\n",
            "         -0.1149,  0.1755,  0.1485, -0.1113,  0.1508,  0.1025,  0.1759,  0.1280,\n",
            "          0.1362, -0.1409, -0.1809, -0.1409, -0.1152,  0.1579,  0.1104,  0.0923,\n",
            "          0.1578, -0.0992, -0.1334, -0.0886, -0.1581,  0.1226,  0.1519,  0.1219,\n",
            "         -0.1564, -0.1314, -0.1499,  0.1098, -0.1661, -0.1869,  0.0976, -0.1528,\n",
            "         -0.1688, -0.1726, -0.1293, -0.1803,  0.0881,  0.1228,  0.1329,  0.1000,\n",
            "          0.1378, -0.0974, -0.1185, -0.0869, -0.1348,  0.1738, -0.0754,  0.1446,\n",
            "          0.1269,  0.1318,  0.1652, -0.1396, -0.0611, -0.1793, -0.1263,  0.1331,\n",
            "          0.0860,  0.2046,  0.1376, -0.1089, -0.1025,  0.1708, -0.1322,  0.1579,\n",
            "          0.1849,  0.1128,  0.1887,  0.0896, -0.1035,  0.1267,  0.1794, -0.1546,\n",
            "          0.1593,  0.1441,  0.1141,  0.1478,  0.1388,  0.1075, -0.1481, -0.1200,\n",
            "         -0.1377,  0.1375,  0.1504,  0.1180,  0.1796,  0.1659,  0.1314, -0.0909,\n",
            "         -0.1119,  0.1438, -0.1881,  0.1306,  0.1779, -0.1197, -0.1238,  0.1550,\n",
            "          0.1638,  0.1603,  0.1199, -0.1723, -0.1336,  0.1756, -0.1553, -0.1354,\n",
            "          0.0984,  0.1149, -0.1446, -0.1430,  0.1441,  0.1719,  0.1342, -0.1543,\n",
            "         -0.1833,  0.1383, -0.1625, -0.1044,  0.1618,  0.1232,  0.1266, -0.1612,\n",
            "          0.1065, -0.1248,  0.0936, -0.1697,  0.1414,  0.1752,  0.1313,  0.1163,\n",
            "          0.1455,  0.1341, -0.1672,  0.1428, -0.1224,  0.1457, -0.1040,  0.1053,\n",
            "         -0.1043, -0.1070,  0.1843, -0.1517,  0.1168, -0.1538,  0.1688, -0.1288,\n",
            "         -0.0960,  0.1388,  0.0970,  0.1337,  0.1055,  0.1269, -0.1772, -0.1937,\n",
            "         -0.1199, -0.1521,  0.1594, -0.0874,  0.1310, -0.1771,  0.1511,  0.1708,\n",
            "          0.1401, -0.1818,  0.1658,  0.1710, -0.0869,  0.0914,  0.1738,  0.1504,\n",
            "          0.1389, -0.1753, -0.1331, -0.1848,  0.1574,  0.1010,  0.1011, -0.1612,\n",
            "         -0.1216,  0.1366,  0.0991,  0.1628, -0.1481, -0.1500,  0.1451,  0.1746,\n",
            "         -0.1580, -0.1273,  0.1050,  0.1646, -0.0931, -0.1464, -0.1257, -0.1662,\n",
            "          0.1698,  0.1758, -0.1215, -0.1525,  0.1159,  0.1041,  0.1669,  0.1705,\n",
            "         -0.1263, -0.1608,  0.1749, -0.1580, -0.1161,  0.1452,  0.1603,  0.1712,\n",
            "          0.1178, -0.1625,  0.1495, -0.1744, -0.1571,  0.1451, -0.1335,  0.1506,\n",
            "         -0.1230, -0.1784, -0.1655, -0.0959, -0.1231,  0.1024,  0.1344,  0.1193,\n",
            "          0.1314,  0.1026, -0.1631, -0.1150, -0.1539, -0.1229, -0.1250,  0.0875,\n",
            "          0.0821,  0.1585,  0.1412,  0.1080, -0.1366, -0.1453,  0.0939, -0.1494,\n",
            "         -0.1378,  0.1890,  0.1644,  0.1447, -0.1451,  0.1189,  0.1315, -0.1168,\n",
            "         -0.1277, -0.1688,  0.1141,  0.0984, -0.1257,  0.1892,  0.1349,  0.1736,\n",
            "         -0.0923, -0.1754, -0.1385, -0.1640, -0.1221,  0.1226, -0.1555,  0.1843,\n",
            "          0.1569,  0.1423,  0.1476, -0.1327,  0.1243,  0.1396, -0.1808, -0.1489,\n",
            "          0.0939,  0.1606,  0.1277,  0.1011,  0.1692, -0.1138,  0.1107, -0.1627,\n",
            "         -0.0945, -0.1349,  0.1245, -0.1021, -0.1664, -0.1290, -0.1075, -0.1061,\n",
            "         -0.1656, -0.1069,  0.1865, -0.1633,  0.1132, -0.1437,  0.1613,  0.1048,\n",
            "          0.1784,  0.1183,  0.1245,  0.1099, -0.1242,  0.1448, -0.1464,  0.1527,\n",
            "         -0.1162,  0.1034, -0.1297, -0.1348, -0.1054, -0.1297, -0.1163,  0.1252,\n",
            "         -0.1815,  0.1625, -0.1284,  0.1008,  0.1860,  0.1664, -0.1150,  0.1305,\n",
            "         -0.1541,  0.1045,  0.1247,  0.1473, -0.1190,  0.1302,  0.1703,  0.1727,\n",
            "         -0.1156,  0.1117,  0.2014, -0.1151, -0.1072, -0.1708, -0.1478,  0.1432,\n",
            "          0.1095, -0.1291, -0.1663,  0.1617,  0.1097,  0.1563, -0.1555,  0.0842,\n",
            "         -0.1353, -0.1315, -0.0871,  0.1318,  0.1643,  0.1151,  0.1654,  0.1195,\n",
            "          0.1492, -0.1661,  0.1358,  0.1154,  0.1917, -0.1680, -0.1849,  0.1622,\n",
            "         -0.0763,  0.1730,  0.1782, -0.1148, -0.1110,  0.1272, -0.1826, -0.1385,\n",
            "          0.1231,  0.0969,  0.1560, -0.1736, -0.1547,  0.1033,  0.1796, -0.1213,\n",
            "          0.1165, -0.1159,  0.1098,  0.0972, -0.0832, -0.1338, -0.1478,  0.1419,\n",
            "         -0.1604, -0.1448, -0.1083,  0.1253,  0.1703, -0.1726, -0.1287, -0.1082,\n",
            "          0.0996, -0.1655,  0.1498, -0.0915, -0.1260,  0.1470, -0.1134,  0.1782,\n",
            "         -0.1487,  0.1691, -0.1647, -0.1543,  0.0913,  0.1892, -0.1417, -0.1280,\n",
            "         -0.1187,  0.1452,  0.1378, -0.1773, -0.1611, -0.1784, -0.0794, -0.1371,\n",
            "         -0.1253,  0.1621,  0.1506,  0.1741,  0.1255, -0.1493,  0.1265,  0.0995,\n",
            "          0.1202,  0.1444, -0.1277,  0.1467,  0.1509, -0.1478,  0.1393, -0.1143,\n",
            "          0.1554, -0.1746, -0.1738,  0.1324, -0.1642,  0.1795,  0.1187,  0.1345,\n",
            "         -0.1232,  0.1613, -0.1437, -0.1110,  0.0817, -0.1149, -0.1659,  0.1312,\n",
            "          0.1576, -0.1030, -0.1178,  0.1780,  0.1092,  0.1364, -0.1464, -0.1815,\n",
            "          0.1073, -0.1323,  0.1310, -0.1244,  0.1091, -0.1083,  0.0843, -0.0891,\n",
            "          0.1851, -0.0955,  0.1665,  0.1778,  0.1549, -0.1017, -0.1580,  0.1602,\n",
            "         -0.1286,  0.1596,  0.1407,  0.0825, -0.1492,  0.1567,  0.1157, -0.1260,\n",
            "          0.1330,  0.1133, -0.1323, -0.0995, -0.1667, -0.1299, -0.1683,  0.1855,\n",
            "          0.1255, -0.1240, -0.1390,  0.1408, -0.1377, -0.1499,  0.1010,  0.1636]])), ('linear2.bias', tensor([0.0008]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A detailed tutorial on saving and loading models in PyTorch can be found [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html)."
      ],
      "metadata": {
        "id": "LOP8sxvJaa8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "모델 학습이 모두 끝난 후, 평가를 test set을 이용해서 진행한다. \n",
        "\n",
        "Once we have trained a model, it is time to evaluate it on a held-out test set. As our dataset consist of randomly generated data points, we need to first create a test set with a corresponding data loader."
      ],
      "metadata": {
        "id": "yPVNQRkEae0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False) "
      ],
      "metadata": {
        "id": "12JpR3GCafVL"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "평가를 위해서 accuracy를 우선 계산해본다. \n",
        "\n",
        "그리고 모델을 평가할 때, 추론을 수행할 때는 gradient 계산이 필요 없으므로 `with torch.no_grad(): ...` 문을 사용해주는 것이 좋다. \n",
        "\n",
        "\n",
        "As metric, we will use accuracy which is calculated as follows:\n",
        "\n",
        "$$acc = \\frac{\\#\\text{correct predictions}}{\\#\\text{all predictions}} = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
        "\n",
        "where TP are the true positives, TN true negatives, FP false positives, and FN the fale negatives. \n",
        "\n",
        "When evaluating the model, we don't need to keep track of the computation graph as we don't intend to calculate the gradients. This reduces the required memory and speed up the model. In PyTorch, we can deactivate the computation graph using `with torch.no_grad(): ...`. Remember to additionally set the model to eval mode."
      ],
      "metadata": {
        "id": "6fscXtUdamXK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "i2T1sXjgF5we"
      },
      "outputs": [],
      "source": [
        "def eval_model(model, data_loader):\n",
        "    model.eval() # Set model to eval mode\n",
        "    true_preds, num_preds = 0., 0.\n",
        "    \n",
        "    with torch.no_grad(): # Deactivate gradients for the following code\n",
        "        for data_inputs, data_labels in data_loader:\n",
        "            \n",
        "            # Determine prediction of model on dev set\n",
        "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
        "            preds = model(data_inputs)\n",
        "            preds = preds.squeeze(dim=1)\n",
        "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
        "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
        "            \n",
        "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
        "            true_preds += (pred_labels == data_labels).sum()\n",
        "            num_preds += data_labels.shape[0]\n",
        "            \n",
        "    acc = true_preds / num_preds\n",
        "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### sigmoid\n",
        "------\n",
        "\n",
        "[sigmoid](https://ko.wikipedia.org/wiki/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C_%ED%95%A8%EC%88%98)는 S자 곡선을 그리는 함수를 의미하며, 대체로 모든 실수 영역에서 [0,1] 또는 [-1,1] 영역의 값을 출력한다. \n",
        "\n",
        "대표적인 sigmoid 함수로는 로지스틱 함수가 있다. \n",
        "\n",
        "$f(x) = \\frac{1}{ 1 + e^{-1} }$"
      ],
      "metadata": {
        "id": "e2ploA28QgQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model, test_data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v4zjoX5awF0",
        "outputId": "e2ce6105-5e4c-4458-c81a-5b86b434b8df"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 94.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-layer 모델\n",
        "-----\n",
        "\n",
        "이번에는 layer 개수가 더 많은 모델을 만들어 보자. "
      ],
      "metadata": {
        "id": "rVsaCUFbSOMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier2(nn.Module):\n",
        "\n",
        "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
        "        super().__init__()\n",
        "        # 네트워크를 구성하는 위한 기반이 되는 layer들을 정의한다. \n",
        "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.linear2 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.linear3 = nn.Linear(num_hidden, num_hidden)\n",
        "        self.linear4 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        x = self.linear1(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.linear3(x)\n",
        "        x = self.act_fn(x)\n",
        "        x = self.linear4(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "dltlGlY5bIk9"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Classifier2(num_inputs=1024, num_hidden=512, num_outputs=1)"
      ],
      "metadata": {
        "id": "0MrcWPwUbyq5"
      },
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwRIjrwyccbR",
        "outputId": "ff44d6b8-4e29-404f-d8b6-fd3c36fb098f"
      },
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Classifier2(\n",
              "  (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (linear3): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (linear4): Linear(in_features=512, out_features=1, bias=True)\n",
              "  (act_fn): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input to the optimizer are the parameters of the model: model.parameters()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "lLyt4WUQSNJt"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, validation_loss = train_model(model2, optimizer, train_loader, loss_module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKi5KMbMb0Oe",
        "outputId": "0ea6c199-525b-48c0-f6a3-0aa349f12e43"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 2/100 [00:00<00:16,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Training Loss: 8.1153, Validation Loss: 0.8324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 7/100 [00:01<00:16,  5.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 005, Training Loss: 2.2585, Validation Loss: 1.2092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 12/100 [00:02<00:15,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Training Loss: 0.9596, Validation Loss: 1.9357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 17/100 [00:02<00:14,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 015, Training Loss: 1.1125, Validation Loss: 1.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 22/100 [00:03<00:13,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 020, Training Loss: 0.6411, Validation Loss: 2.5518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 27/100 [00:04<00:12,  5.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 025, Training Loss: 0.5847, Validation Loss: 2.5573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 31/100 [00:05<00:14,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 030, Training Loss: 0.6429, Validation Loss: 1.9687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 36/100 [00:06<00:15,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 035, Training Loss: 0.5631, Validation Loss: 1.9811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 42/100 [00:08<00:12,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 040, Training Loss: 0.4065, Validation Loss: 2.3151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 47/100 [00:08<00:09,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 045, Training Loss: 0.3888, Validation Loss: 2.1333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 52/100 [00:09<00:08,  5.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 050, Training Loss: 0.2704, Validation Loss: 2.1078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 57/100 [00:10<00:07,  5.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 055, Training Loss: 0.3452, Validation Loss: 1.9631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 62/100 [00:11<00:06,  5.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 060, Training Loss: 0.1357, Validation Loss: 2.7140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 67/100 [00:12<00:05,  5.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 065, Training Loss: 0.1477, Validation Loss: 2.8083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 72/100 [00:13<00:04,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 070, Training Loss: 0.1218, Validation Loss: 2.7219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 77/100 [00:14<00:03,  5.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 075, Training Loss: 0.1203, Validation Loss: 2.9839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 82/100 [00:14<00:03,  5.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 080, Training Loss: 0.1597, Validation Loss: 2.9543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 87/100 [00:15<00:02,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 085, Training Loss: 0.1336, Validation Loss: 2.9301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 92/100 [00:16<00:01,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 090, Training Loss: 0.5923, Validation Loss: 2.4800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 97/100 [00:17<00:00,  5.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 095, Training Loss: 0.3052, Validation Loss: 2.5923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:18<00:00,  5.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, '.', color='b', label='train')\n",
        "plt.plot(validation_loss, '.', color='orange', label='validation')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "EZhszIl4T_8j",
        "outputId": "ef01a92c-0954-4012-da92-35f8e9642471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbe5eeccb50>"
            ]
          },
          "metadata": {},
          "execution_count": 329
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(model2, test_data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSIO_pDacasn",
        "outputId": "97c9eaab-6f0c-4384-e583-684d4c84a90a"
      },
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model: 94.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework: \n",
        "\n",
        "1) Tox21의 다른 타겟의 독성을 선택하여 레이어 개수가 3, 5, 7, 숨겨진 차원의 크기가 128, 256, 1024인 MLP 모델을 훈련시켜 보라. \n",
        "\n",
        "2) 입력 fingerprint의 차원을 128이나 256으로 줄였을 때, 성능의 차이가 생기는지 확인해보라. \n"
      ],
      "metadata": {
        "id": "2Ers--uxTIav"
      }
    }
  ]
}